<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.2//EN"
"http://www.oasis-open.org/docbook/xml/4.2/docbookx.dtd">
<book>
  <title>A High Level Interface to the HDF5 File Format</title>

  <bookinfo>
    <date>May, 11th 2004</date>

    <revhistory>
      <revision>
        <revnumber>0.50</revnumber>

        <date>May 11th, 2004</date>
      </revision>
    </revhistory>

    <author>
      <firstname>Daniel B. Michelson and Anders Henja</firstname>
    </author>

    <copyright>
      <year>2004 by the Swedish Meteorological and Hydrological Institute
      (SMHI), Norrk√∂ping, Sweden</year>
    </copyright>

    <legalnotice>
      <para><emphasis role="bold">By obtaining, using, and/or copying this
      software and/or its associated documentation, you agree that you have
      read, understood, and will comply with the following terms and
      conditions:</emphasis></para>

      <para>Permission to use, copy, modify, and distribute this software and
      its documentation, without fee, is hereby granted, provided that the
      above copyright notice appear in all copies and that both that copyright
      notice and this permission notice appear in supporting documentation,
      and that the name of Swedish Meteorological and Hydrological Institute
      or SMHI not be used in advertising or publicity pertaining to
      distribution of the software without specific, written prior
      permission.</para>
    </legalnotice>

    <legalnotice>
      <para>Copyright Notice and Statement for NCSA Hierarchical Data Format
      (HDF) Software Library and Utilities NCSA HDF5 (Hierarchical Data Format
      5) Software Library and Utilities Copyright 1998, 1999, 2000 by the
      Board of Trustees of the University of Illinois. All rights
      reserved.</para>

      <para>Contributors: National Center for Supercomputing Applications
      (NCSA) at the University of Illinois at Urbana-Champaign (UIUC),
      Lawrence Livermore National Laboratory (LLNL), Sandia National
      Laboratories (SNL), Los Alamos National Laboratory (LANL), Jean-loup
      Gailly and Mark Adler (gzip library).</para>

      <para>Redistribution and use in source and binary forms, with or without
      modification, are permitted for any purpose (including commercial
      purposes)provided that the following conditions are met:</para>

      <orderedlist>
        <listitem>
          <para>Redistributions of source code must retain the above copyright
          notice, this list of conditions, and the following
          disclaimer.</para>
        </listitem>

        <listitem>
          <para>Redistributions in binary form must reproduce the above
          copyright notice, this list of conditions, and the following
          disclaimer in the documentation and/or materials provided with the
          distribution.</para>
        </listitem>

        <listitem>
          <para>In addition, redistributions of modified forms of the source
          or binary code must carry prominent notices stating that the
          original code was changed and the date of the change.</para>
        </listitem>

        <listitem>
          <para>All publications or advertising materials mentioning features
          or use of this software are asked, but not required, to acknowledge
          that it was developed by the National Center for Supercomputing
          Applications at the University of Illinois at Urbana-Champaign and
          to credit the contributors.</para>
        </listitem>

        <listitem>
          <para>Neither the name of the University nor the names of the
          Contributors may be used to endorse or promote products derived from
          this software without specific prior written permission from the
          University or the Contributors</para>
        </listitem>

        <listitem>
          <para>THIS SOFTWARE IS PROVIDED BY THE UNIVERSITY AND THE
          CONTRIBUTORS "AS IS" WITH NO WARRANTY OF ANY KIND, EITHER EXPRESSED
          OR IMPLIED. In no event shall the University or the Contributors be
          liable for any damages suffered by the users arising out of the use
          of this software, even if advised of the possibility of such
          damage.</para>
        </listitem>
      </orderedlist>
    </legalnotice>
  </bookinfo>

  <chapter>
    <title>What's new in release 0.50?</title>

    <sect1>
      <title>Improved debugging</title>

      <para>The debugging possibilities of HLHDF have been improved, now it is
      possible to add your own log handler (i.e. error messages dont have to
      go to stderr). The error messages from the HDF5 library is also possible
      to reroute.</para>
    </sect1>

    <sect1>
      <title>Compression</title>

      <para>The compression handling has been changed. As from now, the
      recommended way to use the compression is by using a compression
      objects. The reason for why this has been modified is that it is quite
      essential to use compression objects when using SZIP (which also is
      supported from this release).</para>
    </sect1>

    <sect1>
      <title>File creation property</title>

      <para>As from now, it is possible to use a file creation property
      instance when writing HDF5 files. The reason for adding this is that it
      can reduce the size of the HDF5 file quite drastically when working with
      small datasets.</para>
    </sect1>

    <sect1>
      <title>C++</title>

      <para>Due to an unfortunate naming of a variable, it was not possible to
      compile HL-HDF with some C++-compilers. The structure
      HL_CompoundTypeDescription contained a variable called typename, this
      conflicted with the C++ primitive so it has been renamed to hltypename.
      This might cause some problems for some users but hopefully the effort
      will not be to high.</para>
    </sect1>

    <sect1>
      <title>This document</title>

      <para>This document has been rewritten to use the DocBook XML
      format.</para>
    </sect1>

    <sect1>
      <title>Miscellaneous</title>

      <para>As usual, some bugfixes have been done since last release.</para>
    </sect1>
  </chapter>

  <chapter>
    <title>The W5 of HL-HDF</title>

    <sect1>
      <title>What?</title>

      <para>HL-HDF is a high level interface to the Heirachical Data Format,
      version 5, developed and maintained by the National Center for
      Supercomputing Applications (NCSA), at the University of Illinois at
      Urbana-Champaign. HDF5 is a file format designed for a maximum of
      flexibility and efficiency and it makes use of modern software
      technology. Briefly, HDF5 has the following characteristics:</para>

      <itemizedlist>
        <listitem>
          <para>Platform independence. For example, an array of native
          floating point values written on one platform will be automatically
          identified, byte-swapped if necessary, and returned as an array of
          native floating point values on another platform.</para>
        </listitem>

        <listitem>
          <para>Built-in compression using the free ZLIB compression library.
          ZLIB is well-known as the compression used in the gzip package and
          it is robust and efficient.</para>
        </listitem>

        <listitem>
          <para>Flexible. HDF5 offers the ability to store virtually any kind
          of scientific data.</para>
        </listitem>
      </itemizedlist>

      <para>The HDF5 project URL is <ulink
      url="http://hdf.ncsa.uiuc.edu/HDF5">http://hdf.ncsa.uiuc.edu/</ulink>
      and links are available to source code, software and copious
      documentation.</para>

      <para>HL-HDF is designed to focus on selected HDF5 functionality and
      make it available to users at a high level of abstraction, the idea
      being to make the management of their data easier. A strong effort has
      been made to ensure that this functionality, although a limited subset
      of HDF5 functionality, provides a general and flexible set of tools for
      managing arbitrary data. Like HDF5, HL-HDF is meant to be used on
      different computer platforms. In practise this means different flavours
      of UNIX and NT. HDF5 may work on other systems, like the Mac, DOS and
      VMS, but NCSA does not support them (yet) which means that HL-HDF does
      not support them either. This is not to say that they will not work on
      these platforms, however.</para>

      <para>Binary tools available with HDF5 will work with files written with
      HL-HDF. For example, <emphasis role="bold">h5dump</emphasis> can be used
      to determine the contents of an HDF5 file written with HL-HDF. A few
      test programs are included with HL-HDF which can read/write raw data
      to/from HDF5 files. These test programs may be useful to users who do
      not wish to write their own routines using the functionality available
      in HL-HDF, but would prefer to rely on a simpler encoder and decoder.
      These programs can also be used as examples of how to write routines
      using HL-HDF.</para>

      <para>HL-HDF is free software and it may be used used by anyone
      according to SMHI's and NCSA's copyright statements containined in this
      document. Users are encouraged to report their feedback to the author,
      and to contribute to its development.</para>
    </sect1>

    <sect1>
      <title>Why?</title>

      <para>This software is designed to facilitate the management of
      scientific data from multiple sources. The integration of observations
      from various observational systems such as weather stations, satellites
      and radars is an area which is receiving increased attention. An
      increasing amount of work is also being carried out on integrating such
      observations with information from numerical models, and in assimilating
      the observations into the models. Unfortunately, most types of data are
      stored in different file formats and little effort has been made to
      facilitate the exchange of data between disciplines such as meteorology,
      hydrology and oceanography. Since SMHI is the national agency
      responsible for operational activities in all three of these
      disciplines, it would obviously be beneficial to these operations if a
      rationalization of data management procedures can be realized. This is
      the reason why the HL-HDF software has been developed.</para>

      <para>Another important reason why HL-HDF has been developed is that it
      facilitates the management of multi-source data for pure research and
      development activities. This is due to the software's flexibility which
      provides a platform for managing virtually any variable and combination
      of variables imaginable.</para>

      <para>Due to HDF5's platform independent nature, its use can even be
      considered for exchange between organizations, either domestically or
      internationally. Its built-in compression is efficient which increases
      the potential amount of data available in archives and helps make them
      more useful.</para>
    </sect1>

    <sect1>
      <title>Where?</title>

      <para>HL-HDF has been developed for use in three general areas:</para>

      <orderedlist>
        <listitem>
          <para>General purpose research and development.</para>
        </listitem>

        <listitem>
          <para>Data management. HL-HDF can be used wherever there are
          requirements put on managing scientific data, whether it be with a
          small amount of data by a single person or with a comprehensive
          archive by a large organization.</para>
        </listitem>

        <listitem>
          <para>Data exchange. HL-HDF can be used almost anywhere data
          exchange is required. This can be within an organization or between
          organizations, either domestically or internationally.</para>
        </listitem>
      </orderedlist>
    </sect1>

    <sect1>
      <title>When?</title>

      <para>HL-HDF has been developed during the first half of 2000 on a small
      budget as a one-off pilot project. This means that there is no ongoing
      project group and no official support. The objective has been to develop
      HL-HDF and then release it for anyone to use as he or she pleases.
      Feedback is naturally welcome to the e-mail address on this document's
      front page, and we hope to be able to incorporate improvements as best
      we can.</para>

      <para>The timing of HL-HDF has been fortunate. Had we gotten underway
      earlier, we probably would have chosen HDF4. Had we waited until later,
      then several of our applications may have chosen inferiour file formats.
      It feels as though this work has been done in the right place at the
      right time.</para>
    </sect1>

    <sect1>
      <title>Who?</title>

      <para>Who can use HL-HDF? Anyone who works with scientific data can use
      HL-HDF, whether it be research and development with a limited amount of
      data or management of vast volumes of data in operational
      environments.</para>

      <para>Who has worked on this project? The programming has been performed
      by Anders Henja from Adcore, Norrk√∂ping. Daniel Michelson has
      coordinated the project. Mike Folk and Quincey Koziol of the HDF group
      at the NCSA have also been very helpful. An "ad hoc reference group" has
      followed the project's progress. This group consists of the following
      people:</para>

      <table>
        <title></title>

        <tgroup cols="2">
          <colspec align="left" colnum="1" colwidth="110" />

          <colspec align="left" colnum="2" colwidth="300" />

          <tbody>
            <row>
              <entry>√òystein God√∏y</entry>

              <entry>The Norwegian Meteorological Institute</entry>
            </row>

            <row>
              <entry>Harri Hohti</entry>

              <entry>Finnish Meteorological Institute</entry>
            </row>

            <row>
              <entry>Otto Hyv√§rinen</entry>

              <entry>Finnish Meteorological Institute</entry>
            </row>

            <row>
              <entry>Pirkko Pylkk√∂</entry>

              <entry>Finnish Meteorological Institute</entry>
            </row>

            <row>
              <entry>Per K√•llberg</entry>

              <entry>European Centre for Medium Range Weather Forecasting and
              SMHI</entry>
            </row>

            <row>
              <entry>Hans Alexandersson</entry>

              <entry>SMHI</entry>
            </row>

            <row>
              <entry>Bengt Carlsson</entry>

              <entry>SMHI</entry>
            </row>

            <row>
              <entry>Adam Dybbroe</entry>

              <entry>SMHI</entry>
            </row>

            <row>
              <entry>J√∂rgen Sahlberg</entry>

              <entry>SMHI</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
    </sect1>
  </chapter>

  <chapter>
    <title>Compilation and Installation</title>

    <sect1>
      <title>Requirements</title>

      <para>The Heirarchical Data Format, version 5, must be built and
      accessible. Source code and prebuilt releases of HDF5 are available from
      the National Centre for Supercomputing Applications at <ulink
      url="ftp://hdf.ncsa.uiuc.edu/HDF5/">ftp://hdf.ncsa.uiuc.edu/HDF5</ulink>.
      Follow the documentation from NCSA if you plan on building HDF5
      yourself. An extremely important requirement is that an ANSI-compliant C
      compiler be used. Some native compilers cannot handle ANSI C and HL-HDF
      will therefore not build.</para>

      <sect2>
        <title>UNIX</title>

        <para>A number of GNU tools are required, or at least highly
        recommended, in order to build HL-HDF. These tools are:</para>

        <orderedlist>
          <listitem>
            <para><command>gzip</command> (including zlib), version 1.1.0 or
            higher</para>
          </listitem>

          <listitem>
            <para><command>tar</command></para>
          </listitem>

          <listitem>
            <para><command>make</command>, GNU Make version 3.7x or higher (or
            compatible) all of which which are available from <ulink
            url="http://www.gnu.org/">http://www.gnu.org/</ulink>. GNU C (and
            Fortran) compilers can also be retrieved from this site.</para>
          </listitem>
        </orderedlist>

        <para>In order for <command>gzip</command> to work, the ZLIB
        compression library must be compiled and installed. ZLIB is available
        at <ulink
        url="http://www.cdrom.com/pub/infozip/zlib/">http://www.cdrom.com/pub/infozip/zlib/</ulink>.</para>
      </sect2>

      <sect2>
        <title>Windows NT</title>

        <para>The free WiZ package, available from <ulink
        url="http://www.cdrom.com/pub/infozip/WiZ.html">http://www.cdrom.com/pub/infozip/WiZ.html</ulink>,
        or the proprietary WinZip package, available from <ulink
        url="http://www.winzip.com/">http://www.winzip.com/</ulink>, should be
        installed and accessible. If you choose to link in the pre-compiled
        HDF5 libs, then you'll have to use the Microsoft Visual C++ compiler,
        since this is what was used to build the HDF5 package.</para>
      </sect2>

      <sect2>
        <title>Mac</title>

        <para>No support yet.</para>
      </sect2>

      <sect2>
        <title>VMS</title>

        <para>No support yet.</para>
      </sect2>
    </sect1>

    <sect1>
      <title>Compilation</title>

      <para>Make sure that all the requirements presented in the previous
      Section are met.</para>

      <sect2>
        <title>UNIX</title>

        <para>The first step is to unpack the distribution. For ths purposes
        of this documentation, the path <emphasis
        role="bold">/usr/local/src</emphasis> will be the root of the
        installation. Unpack the distribution with <command>/usr/local/src %
        tar xvzf hlhdf_r0.34.tgz</command> This will create a directory called
        <emphasis role="bold">hlhdf</emphasis> and the distribution will be
        placed in it. If the above arguments fail, then you have not used GNU
        tar.</para>

        <para>HL-HDF has a <command>configure</command> script to determine
        paths to compilers, headers and libraries. In short it tries to find
        everything HL-HDF needs to be built.</para>

        <para>Execute the <emphasis role="bold">configure</emphasis> script.
        The most relevant arguments are:</para>

        <table>
          <title></title>

          <tgroup cols="2" id="configure" xreflabel="Configure options">
            <colspec align="left" colnum="1" colwidth="110" />

            <colspec align="left" colnum="2" colwidth="300" />

            <tbody>
              <row>
                <entry>--prefix=PATH</entry>

                <entry>Set the root of the installation path. Defaults to
                <emphasis role="bold">'/usr/local/hlhdf'</emphasis></entry>
              </row>

              <row>
                <entry>--with-zlib=INC,LIB</entry>

                <entry>Use GNU ZLIB compression headers located at <emphasis
                role="bold">INC</emphasis> and library located at <emphasis
                role="bold">LIB</emphasis></entry>
              </row>

              <row>
                <entry>--with-szlib=INC,LIB</entry>

                <entry>Use SZLIB compression headers located at <emphasis
                role="bold">INC</emphasis> and library located at <emphasis
                role="bold">LIB</emphasis>, this requires HDF5 versions &gt;=
                1.6.0</entry>
              </row>

              <row>
                <entry>--with-hdf5=INC,LIB</entry>

                <entry>Use the HDF5 headers located at <emphasis
                role="bold">INC</emphasis> and libraries located at <emphasis
                role="bold">LIB</emphasis></entry>
              </row>

              <row>
                <entry>--with-python=yes|no</entry>

                <entry>Configure in Python support. Default is <emphasis
                role="bold">yes</emphasis>. Enables building a Python
                interface.</entry>
              </row>

              <row>
                <entry>--with-fortran=yes|no</entry>

                <entry>Configure with Fortran. Default is <emphasis
                role="bold">no</emphasis>. Useful if integrating with F77
                code.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>

        <para>There are a few more arguments and they are listed by
        executing</para>

        <para><literal><command>/usr/local/src/hlhdf % ./configure
        -help</command></literal> If <emphasis
        role="bold">configure</emphasis> fails, which is unlikely, then you
        may be in trouble. See Section <xref linkend="platform" /> for
        platform-specific notes. The bottom line is that you may have to make
        some manual adjustments to your configuration files.</para>

        <para>If configuration has been carried out without any problems then
        you're ready to build HL-HDF with:</para>

        <para><command>/usr/local/src/hlhdf % make</command> This will
        generate the library <emphasis role="bold">libhlhdf.a</emphasis>
        located in the <emphasis
        role="bold">/usr/local/src/hlhdf/hlhdf</emphasis> directory.</para>
      </sect2>

      <sect2>
        <title>Windows NT</title>

        <para>Unpack the distribution using WiZ or WinZip. The following build
        instructions apply to the Microsoft Visual C++ 6.0 compiler.</para>

        <orderedlist>
          <listitem>
            <para>Start a new project by selecting "File - New - Projects -
            Win32 Static Library". Add appropriate <emphasis
            role="bold">Project name</emphasis> (hlhdf) and <emphasis
            role="bold">Location</emphasis> in this same window. No
            precompiled headers or MFC support is needed.</para>
          </listitem>

          <listitem>
            <para>Tools - Options - Directories. Make sure you add the path to
            the HDF5 header files.</para>
          </listitem>

          <listitem>
            <para>Project - Add to Project - Files. Go to where the source and
            header files for HL-HDF are located and add them all.</para>
          </listitem>

          <listitem>
            <para>Project - Settings - C/C++. Set appropriate warning level
            and optimization.</para>
          </listitem>

          <listitem>
            <para>Build - Build hlhdf.lib</para>
          </listitem>
        </orderedlist>

        <para>This should generate the file <emphasis
        role="bold">hlhdf.lib</emphasis> in the <emphasis
        role="bold">Debug</emphasis> directory.</para>
      </sect2>
    </sect1>

    <sect1>
      <title>Testing</title>

      <sect2>
        <title>UNIX</title>

        <para>An optional testing of the HL-HDF library may be performed by
        compiling a test program located in the <emphasis
        role="bold">/usr/local/src/hlhdf/test</emphasis> directory.</para>

        <para>Simply move to this directory and type</para>

        <para><command>/usr/local/src/hlhdf/test % make</command> which should
        build the test program <emphasis
        role="bold">testRaveObject</emphasis>.</para>

        <para>This program can be used to test read or test write an
        artificial image along with a number of different kinds of header
        parameters. To test the reading, execute</para>

        <para><command>/usr/local/src/hlhdf/test % testRaveObject
        read</command> and an ASCII representation of the contents of
        <emphasis role="bold">rave_image_file.hdf</emphasis> will be written
        to <emphasis role="bold"><command>stdout</command></emphasis>.</para>

        <para>To test writing, execute</para>

        <para><command>/usr/local/src/hlhdf/test % testRaveObject
        write</command> and and an ASCII representation of the contents of
        <emphasis role="bold">rave_image_file.hdf</emphasis> will be written
        to <emphasis role="bold"><command>stdout</command></emphasis> and the
        file itself will be re-written.</para>

        <para>Alternatively, if <emphasis
        role="bold">rave_image_file.hdf</emphasis> doesn't exist, execute the
        test program with the <command>write</command> argument first to
        create the file, and then <command>read</command> it to examine its
        contents.</para>

        <para>If this test program works, then you can be confident that the
        HL-HDF library works! (The above use of "rave" in the test program and
        file refers to Radar Analysis and Visualization Environment software,
        which is freely available software maintained by SMHI).</para>
      </sect2>

      <sect2>
        <title>Windows NT</title>

        <para>Testing involves creating a new project in Microsoft Visual C++.
        This same strategy should be applied when building the <emphasis
        role="bold">hlenc</emphasis>, <emphasis role="bold">hldec</emphasis>
        and <emphasis role="bold">hllist</emphasis> binaries.</para>

        <orderedlist>
          <listitem>
            <para>Start a new project by selecting "File - New - Projects -
            Win32 Console Application". Add appropriate <emphasis>Project
            name</emphasis> (test) and <emphasis>Location</emphasis> in this
            same window. Then select "An empty project".</para>
          </listitem>

          <listitem>
            <para>Tools - Options - Directories. Add paths to the HL-HDF
            header files and the newly build library <emphasis
            role="bold">hlhdf.lib</emphasis>. Make sure the paths to the HDF5
            headers and library are there as well.</para>
          </listitem>

          <listitem>
            <para>Project - Add to Project - Files. Go to where <emphasis
            role="bold">test_raveobject.c</emphasis> is located and add
            it.</para>
          </listitem>

          <listitem>
            <para>Project - Settings - C/C++. Set appropriate warning level
            and optimization.</para>
          </listitem>

          <listitem>
            <para>Project - Settings - Link - Object/library modules. Add
            <emphasis role="bold">hlhdf.lib hdf5.lib zlib.lib</emphasis> in
            this order to the beginning of this list.</para>
          </listitem>

          <listitem>
            <para>Build - Build test.exe</para>
          </listitem>

          <listitem>
            <para>Open a DOS console and change to the directory containing
            <emphasis role="bold">test.exe</emphasis>. Execute <command>test
            write</command> to create an HDF test file. Execute <command>test
            read</command> to query the contents of this file. If this works,
            then you can be confident that your HL-HDF library works.</para>
          </listitem>
        </orderedlist>
      </sect2>
    </sect1>

    <sect1>
      <title>Installation</title>

      <sect2>
        <title>UNIX</title>

        <para>Execute</para>

        <para><command>/usr/local/src/hlhdf % make install</command> and the
        header files, libraries, binaries, scripts and an MK-file will be
        installed to the <emphasis role="bold">include</emphasis>, <emphasis
        role="bold">lib</emphasis>, <emphasis role="bold">bin</emphasis> and
        <emphasis role="bold">mkf</emphasis> directories located under the
        path specified by the <emphasis
        role="bold"><command>prefix</command></emphasis> variable which was
        used when HL-HDF was build. HL-HDF is complete when this has been
        carried out. For information on how to compile and install the Python
        interface, see Chapter<xref linkend="platform" />.</para>
      </sect2>

      <sect2>
        <title>Windows NT</title>

        <para>A specific installation has not been defined. It is up to the
        user to place the headers, library, and binaries in appropriate
        locations.</para>
      </sect2>
    </sect1>

    <sect1>
      <title id="platform" xreflabel="Platform notes">Platform Notes</title>

      <para>HL-HDF has been built on a number of systems, most of which are
      different flavours of UNIX. Unfortunately HDF5 is not available for any
      form of VMS or other arcane operating system such as DOS. HL-HDF was
      developed with the intention that is should be possible to build it
      on most platforms, however since we only have a limited set of different
      machines, it is impossible for us to say on what machines it is possible
      to build.</para>

      <para><emphasis role="bold">If the pre-compiled binaries are installed,
      the file <emphasis role="bold">mkf/hldef.mk</emphasis> has to be
      modified manually to point to the locations of the HDF5 installation,
      the ZLIB installation, the compiler, etc.</emphasis></para>

      <para>
      Development and testing has in this release been done on a PC Linux, Mandrake 9.1.
      </para>
    </sect1>
  </chapter>

  <chapter>
    <title>Fundamentals</title>

    <para>This Chapter presents HL-HDF's building blocks so that the user will
    have a knowledge of the proper terminology prior to working hands-on with
    the library. To make the most of the functionality in HL-HDF, users should
    have a working knowledge of the C programming language.</para>

    <para>This documentation is designed to be complimentary to the official
    HDF5 documentation and users should refer to the official set for more
    detail on HDF5's internal mechanisms.</para>

    <sect1>
      <title>The Hierarchy</title>

      <para>The "H" in HDF stands for "Heirarchical" and this describes how
      HDF files are structured. An HDF file can be likened to a file system.
      At the root of the file system is a period (".") or a slash ("/") and
      the file may consist of an arbitrary number of levels of data, like
      subdirectories in a file system. For example, if a NOAA satellite image
      containing several spectral bands of data are stored in this manner, one
      way of doing so could look like this: <literallayout>
.
/NOAA 14/
/NOAA 14/info
/NOAA 14/info/xsize
/NOAA 14/info/ysize
/NOAA 14/Channel 1/
/NOAA 14/Channel 2/
/NOAA 14/Channel 3/
        </literallayout>where <emphasis role="bold">info</emphasis> is an
      object containing header information. The same strategy could be used to
      store several polar scans of weather radar data, for example.
      Alternatively, a numerical weather prediction model state could be
      represented in part using GRIB descriptors like this: <literallayout>
.
/Level 0/
/Level 0/Type 105/
/Level 0/Type 105/Parameter 11/
/Level 0/Type 102/
/Level 31/
/Level 31/Type 109/
/Level 31/Type 109/Parameter 11/
        </literallayout>Or, why not a point from a weather station containing
      wind speed and direction values: <literallayout>
.
/WMO 02064/
/WMO 02064/dd/
/WMO 02064/ff/
/WMO 02036/
        </literallayout></para>
    </sect1>

    <sect1>
      <title>HL-HDF Building Blocks</title>

      <para>HL-HDF provides a number of building blocks which are defined in
      detail in the header file <emphasis
      role="bold">vhlhdf.h</emphasis>.</para>

      <sect2>
        <title>Datatype</title>

        <para>A <emphasis role="bold">Datatype</emphasis> is a data
        representation consisting of atomic data types such as a string, byte,
        integer, floating point value of a given word size, or in the form of
        a C <emphasis role="bold">struct</emphasis> containing combinations of
        atomic types. A <emphasis role="bold">Datatype</emphasis> is used to
        describe the characteristics of one's data, and a number of <emphasis
        role="bold">Datatype</emphasis>s may collectively constitute a header.
        Every <emphasis role="bold">Datatype</emphasis> is given a name which
        is stored in a string; this string is used to represent the <emphasis
        role="bold">Datatype</emphasis> in the HDF file.</para>
      </sect2>

      <sect2>
        <title>Attribute</title>

        <para>An <emphasis role="bold">Attribute</emphasis> contains a string
        used to identify it, an array with up to four dimensions, and a number
        of <emphasis role="bold">Datatype</emphasis>s describing that
        <emphasis role="bold">Attribute</emphasis>. An <emphasis
        role="bold">Attribute</emphasis> is an appropriate object for storing
        point values, for example, and storing time series of them is enabled
        in the <emphasis role="bold">Attribute</emphasis> object.</para>
      </sect2>

      <sect2>
        <title>Reference</title>

        <para>A <emphasis role="bold">Reference</emphasis> is basically a
        pointer to another object. A <emphasis
        role="bold">Reference</emphasis> can only be pointed to a <emphasis
        role="bold">Datatype</emphasis>, a <emphasis
        role="bold">Dataset</emphasis> or a <emphasis
        role="bold">Group</emphasis>. Using the <emphasis
        role="bold">Reference</emphasis> might be needed when generating HDF5
        images, since a reference to a palette has to be inserted in the
        <emphasis role="bold">Dataset</emphasis> object.</para>
      </sect2>

      <sect2>
        <title>Dataset</title>

        <para>A <emphasis role="bold">Dataset</emphasis> is a higher level
        object and contains a string used to identify it, an optional array
        with between one and four dimensions, an array of <emphasis
        role="bold">Datatype</emphasis>s, and an array of <emphasis
        role="bold">Attribute</emphasis>s. A <emphasis
        role="bold">Dataset</emphasis> is an appropriate object for storing
        profile (transect) or image data, and it can be used to store time
        series of a given variable.</para>
      </sect2>

      <sect2>
        <title>Group</title>

        <para>A <emphasis role="bold">Group</emphasis> is the highest level
        object and consists of a string used to identify it and an arbitrary
        combination of any of the <emphasis role="bold">Datatype</emphasis>,
        <emphasis role="bold">Attribute</emphasis>, <emphasis
        role="bold">Dataset</emphasis>, and <emphasis
        role="bold">Group</emphasis> building blocks. The root of any HDF5
        file (denoted with "." or "/") is always a <emphasis
        role="bold">Group</emphasis>.</para>
      </sect2>

      <sect2>
        <title>Node</title>

        <para>A <emphasis role="bold">Node</emphasis> is a term used in the
        HL-HDF code to refer to any of the above mentioned building blocks in
        an HDF5 file. In other words, any given object in the heirarchy is a
        <emphasis role="bold">Node</emphasis>.</para>
      </sect2>

      <sect2>
        <title>Scalar</title>

        <para>A <emphasis role="bold">Scalar</emphasis> is an individual
        value.</para>
      </sect2>

      <sect2>
        <title>Atomic</title>

        <para>In HDF5 the predefined datatypes (for example 'int', 'short',
        ...) are referred to as <emphasis role="bold">Atomic</emphasis>, as
        opposed to the <emphasis role="bold">Compound</emphasis> datatypes
        which are a combination of <emphasis role="bold">Atomic</emphasis>
        datatypes.</para>
      </sect2>
    </sect1>

    <sect1>
      <title>C Header Definitions</title>

      <para>The previous section presented the principles of HL-HDF building
      blocks. This section presents their actual names and their definitions,
      along with some fundamentals from HDF5 itself.</para>

      <sect2>
        <title>hid_t</title>

        <para>This variable comes from HDF5 and is a type for managing
        references to nodes. Each node reference is represented as an integer
        and <emphasis role="bold">hid_t</emphasis> keeps track of them.</para>
      </sect2>

      <sect2>
        <title>herr_t</title>

        <para>This variable comes from HDF5 and is a type for handling error
        codes.</para>
      </sect2>

      <sect2>
        <title>hsize_t</title>

        <para>This variable comes from HDF5 and represents a native
        multiple-precision integer.</para>
      </sect2>

      <sect2>
        <title>HL_Type</title>

        <para>This is an enumeration variable designed to identify the type of
        a given node. <emphasis role="bold">HL_Type</emphasis> can be any of
        following possible values:</para>

        <literallayout>
UNDEFINED_ID=-1 
ATTRIBUTE_ID=0
GROUP_ID=1
DATASET_ID=2
TYPE_ID=3
REFERENCE_ID=4
          </literallayout>
      </sect2>

      <sect2>
        <title>HL_DataType</title>

        <para>This is an enumeration variable designed to identify the type of
        data in a given node. <emphasis role="bold">HL_DataType</emphasis> can
        be any of the following possible values:</para>

        <literallayout>
DTYPE_UNDEFINED_ID=-1
HL_SIMPLE=0
HL_ARRAY=1
          </literallayout>

        <para>When new nodes are initiated, they contain <emphasis
        role="bold">HL_DataType=DTYPE_UNDEFINED</emphasis>.</para>
      </sect2>

      <sect2>
        <title>HL_NodeMark</title>

        <para>This is an enumeration variable designed to keep track of the
        status of a given node. <emphasis role="bold">HL_NodeMark</emphasis>
        can be any of the following possible values:</para>

        <literallayout>
NMARK_ORIGINAL=0
NMARK_CHANGED=1
NMARK_SELECT=2
          </literallayout>

        <para>A node with <emphasis
        role="bold">HL_NodeMark=NMARK_CHANGED</emphasis> can be used to mark
        that it has been modified. A node with <emphasis
        role="bold">HL_NodeMark=NMARK_SELECT</emphasis> is used to indicate
        that this node should be read when performing a fetch.</para>
      </sect2>

      <sect2>
        <title>HL_Node</title>

        <para>This is a single node and is defined in the following
        structure:</para>

        <literallayout>
typedef struct HL_Node {
   HL_Type type;           /* the type of node */
   char name[256];         /* the node's name */
   int ndims;              /* the number of dimensions in the array */
   hsize_t dims[4];        /* the dimensions of each of ndims */
   unsigned char* data;    /* actual data (fixed type) */
   unsigned char* rawdata; /* actual raw data, machine dependent */
   char format[64];        /* the string representation of the data type */
   hid_t typeId;           /* reference to HDF's internal type management */
   size_t dSize;           /* size of one value in data (fixed type) */
   size_t rdSize;          /* size of one value in raw data, machine dependent */
   HL_DataType dataType;   /* identifies whether data is single or an array */
   hid_t hdfId;            /* like typeId: for internal use */
   HL_NodeMark mark;       /* is this node marked? */
   HL_CompoundTypeDescription* compoundDescription; /* a list of compound
type descriptions*/
} HL_Node;
           </literallayout>
      </sect2>

      <sect2>
        <title>HL_NodeList</title>

        <para>This type is a list of nodes and is structured like this:</para>

        <literallayout>
typedef struct {
   char filename[256];  /* a file string */
   char tmp_name[512];  /* temporary names for internal use */
   int nNodes;          /* the number of nodes in the list */
   int nAllocNodes;     /* the number of allocated nodes in the list; internal */
   HL_Node** nodes;     /* the nodes themselves */
} HL_NodeList;
          </literallayout>
      </sect2>

      <sect2>
        <title>HL_CompoundTypeAttribute</title>

        <para>This type is designed to describe an individual node with a
        complicated structure, ie. one which consists of more than atomic data
        types. It contains all the information required to interpret the
        contents of the node:</para>

        <literallayout>
typedef struct {
   char attrname[256];  /* the Attribute's name */
   size_t offset;       /* the offset to where the data begins */
   char format[256];    /* the string representation of the atomic data type */
   int ndims;           /* the number of dimensions in the array */
   size_t dims[4];      /* the dimensions of each of ndims */
} HL_CompoundTypeAttribute;
          </literallayout>
      </sect2>

      <sect2>
        <title>HL_CompoundTypeDescription</title>

        <para>This type is a list of <emphasis
        role="bold">HL_CompoundTypeAttribute</emphasis>s. The reason why it's
        called "Description" is that it acts more like meta data than actual
        data, since it's just a collection of other nodes which may contain
        data, and is therefore more of a description than anything else. It is
        structured like this:</para>

        <literallayout>
typedef struct {
   char hltypename[256];          /* the list's name */
   unsigned long objno[2];      /* markers used to tag nodes in the list */
   size_t size;                 /* size of this data type */
   int nAttrs;                  /* the number of attributes in the list */
   int nAllocAttrs;             /* the number of allocated attributes */
   HL_CompoundTypeAttribute** attrs; /* the attributes themselves */
} HL_CompoundTypeDescription;
          </literallayout>
      </sect2>

      <sect2>
        <title>HL_Compression</title>

        <para>A new way of using compression have been added since szlib
        requires more detailes compression instructions depending on what
        dataset that is beeing compressed.</para>

        <para><literallayout>
typedef struct {
 /* The wanted compression type,
  * CT_NONE, CT_ZLIB, CT_SZLIB.
  * 
  * If CT_ZLIB is used, the member level need to be set to a value between
  * 1-9
  * If CT_SZLIB is used, the members szlib_mask, szlib_px_per_block needs
  * to be set.
  */
  HL_CompressionType type;

 /* The compression level when using ZLIB compression,
  * compression is indicated by values between 1-9, if set
  * to 0 this will not be seen as compression
  */
 int level;

 /* Mask when using szlib compression, the mask can be set up from two
  * different sets of options.
  * ---------------------------------------------------------------
  * H5_SZIP_CHIP_OPTION_MASK | Compresses exactly as in hardware.
  * H5_SZIP_ALLOW_K13_OPTION_MASK | Allows k split = 13 compression mode. (Default)
  * ---------------------------------------------------------------
  * H5_SZIP_EC_OPTION_MASK | Selects entropy coding method. (Default)
  * H5_SZIP_NN_OPTION_MASK | Selects nearest neighbor coding method.
  * ---------------------------------------------------------------
  * Where the paired options are mutual exclusive, i.e. it is possible
  * to set the szlib_mask to H5_SZIP_CHIP_OPTION_MASK|H5_SZIP_EC_OPTION_MASK
  * but not to H5_SZIP_CHIP_OPTION_MASK|H5_SZIP_ALLOW_K13_OPTION_MASK
  */
  unsigned int szlib_mask;

  /* The block size must be be even, with typical values being 8, 10, 16, and 32.
   * The more pixel values vary, the smaller this number should be
   */
  unsigned int szlib_px_per_block;
 } HL_Compression;
 </literallayout></para>
      </sect2>

      <sect2>
        <title>HL_FileCreationProperty</title>

        <para><literallayout>
typedef struct {
   /* See hdf5 documentation for H5Pget_version for purpose */
   HL_PropertyVersion version;
   
   /* See hdf5 documentation for H5Pset_userblock and H5Pget_userblock for purpose */
   hsize_t userblock;

   /* See hdf5 documentation for H5Pset_sizes and H5Pget_sizes for purpose */
   HL_PropertySize sizes;
   
   /* See hdf5 documentation for H5Pset_sym_k and H5Pget_sym_k for purpose */
   HL_PropertySymK sym_k;

   /* See hdf5 documentation for H5Pset_istore_k and H5Pget_istore_k for purpose */
   int istore_k;

   /* This is actually in the File access properties but atm it feels like overkill
    * to provide the user with functionality to fine tune all these variables
    * since its only the meta_block_size we have found any use for.
    * If the value of meta_block_size is 2048, then we are using default value
    * and the default FILE_ACCESS_PROPERTY will be used. */
   hsize_t meta_block_size;
} HL_FileCreationProperty;
 </literallayout></para>
      </sect2>
    </sect1>
  </chapter>

  <chapter>
    <title>Library Reference</title>

    <para>What follows is a list of HL-HDF C functions, along with their
    arguments and descriptions on how to use them. The functions given in this
    section are those declared in the header files in the HL-HDF source. The
    functions are grouped according to what they are designed to do.</para>

    <sect1>
      <title>General functions</title>

      <sect2>
        <title>initHlHdf</title>

        <para>void <emphasis role="bold">initHlHdf</emphasis>()</para>

        <para>Initiates the HL-HDF functions. This call must be made before
        anything else is done.</para>

        <para>Returns nothing.</para>
      </sect2>

      <sect2>
        <title>disableErrorReporting</title>

        <para>void <emphasis
        role="bold">disableErrorReporting</emphasis>()</para>

        <para>Deactivates HDF5 debugging.</para>

        <para>Returns nothing.</para>
      </sect2>

      <sect2>
        <title>enableErrorReporting</title>

        <para>void <emphasis
        role="bold">enableErrorReporting</emphasis>()</para>

        <para>Activates HDF5 debugging.</para>

        <para>Returns nothing.</para>
      </sect2>

      <sect2>
        <title>debugHlHdf</title>

        <para>void <emphasis role="bold">debugHlHdf</emphasis>(int
        flag)</para>

        <para>Sets the debug mode.</para>

        <para><emphasis role="bold">flag</emphasis> can be 0 (no debugging), 1
        (debug only HL-HDF), or 2 (debug HL-HDF and HDF5).</para>

        <para>Returns nothing.</para>
      </sect2>

      <sect2>
        <title>isHdf5File</title>

        <para>int <emphasis role="bold">isHdf5File</emphasis>(const char*
        filename)</para>

        <para>Checks whether <emphasis role="bold">filename</emphasis> is an
        HDF5 file.</para>

        <para>Returns 1 if it is and 0 otherwise.</para>
      </sect2>

      <sect2>
        <title>openHlHdfFile</title>

        <para>hid_t <emphasis role="bold">openHlHdfFile</emphasis>(const char*
        filename,const char* how)</para>

        <para>Opens an HDF5 file.</para>

        <para><emphasis role="bold">filename</emphasis>: String containing the
        files name.</para>

        <para><emphasis role="bold">how</emphasis>: What mode that should be
        used for opening the file, can be 'r' (read only), 'w' (write only) or
        'rw' (read and write).</para>

        <para>Returns the <emphasis role="bold">hid_t</emphasis> reference
        upon success otherwise -1.</para>
      </sect2>

      <sect2>
        <title>createHlHdfFile</title>

        <para>hid_t <emphasis role="bold">createHlHdfFile</emphasis>(const
        char* filename)</para>

        <para>Creates an HDF5 file <emphasis role="bold">filename</emphasis>,
        if the file already exists it will be truncated.</para>

        <para><emphasis role="bold">filename</emphasis> is the name of the
        file to be created.</para>

        <para>Returns the <emphasis role="bold">hid_t</emphasis> reference
        upon success otherwise -1.</para>
      </sect2>

      <sect2>
        <title>closeHlHdfFile</title>

        <para>herr_t <emphasis role="bold">closeHlHdfFile</emphasis>(hid_t
        file_id)</para>

        <para>Closes the HDF5 file with the <emphasis
        role="bold">hid_t</emphasis> reference <emphasis
        role="bold">file_id</emphasis>.</para>

        <para>Returns a value greater or equal to 0 upon success otherwise a
        negative value.</para>
      </sect2>

      <sect2>
        <title>getFixedType</title>

        <para>hid_t <emphasis role="bold">getFixedType</emphasis>(hid_t
        type)</para>

        <para>Translates from the datatype specified by <emphasis
        role="bold">type</emphasis> to a native datatype.</para>

        <para>Returns the native datatype <emphasis
        role="bold">hid_t</emphasis> upon success, or a negative value on
        failure.</para>
      </sect2>

      <sect2>
        <title>translateCharToDatatype</title>

        <para>hid_t <emphasis
        role="bold">translateCharToDatatype</emphasis>(const char*
        dataType)</para>

        <para>Creates an HDF5 datatype <emphasis role="bold">hid_t</emphasis>
        from the string representation <emphasis
        role="bold">dataType</emphasis>.</para>

        <para><emphasis role="bold">dataType</emphasis> can be one of:
        <emphasis role="bold">char, schar, uchar, short, ushort, int, uint,
        long, ulong, llong, ullong, float, double, hsize, hssize,
        herr</emphasis> or <emphasis role="bold">hbool.</emphasis></para>

        <para>Returns a value &lt; 0 upon failure, otherwise a <emphasis
        role="bold">hid_t</emphasis> reference to the new type.</para>
      </sect2>

      <sect2>
        <title>getTypeNameString</title>

        <para>char* <emphasis role="bold">getTypeNameString</emphasis>(hid_t
        type)</para>

        <para>Translates the HDF5 type <emphasis role="bold">type</emphasis>
        to an HDF5 string representation of the datatype. The returned string
        can be one of: <emphasis role="bold"> H5T_STD_I8BE, H5T_STD_I8LE,
        H5T_STD_I16BE, H5T_STD_I16LE, H5T_STD_I32BE, H5T_STD_I32LE,
        H5T_STD_I64BE, H5T_STD_I64LE, H5T_STD_U8BE, H5T_STD_U8LE,
        H5T_STD_U16BE, H5T_STD_U16LE, H5T_STD_U32BE, H5T_STD_U32LE,
        H5T_STD_U64BE, H5T_STD_U64LE, H5T_NATIVE_SCHAR, H5T_NATIVE_UCHAR,
        H5T_NATIVE_SHORT, H5T_NATIVE_USHORT, H5T_NATIVE_INT, H5T_NATIVE_UINT,
        H5T_NATIVE_LONG, H5T_NATIVE_ULONG, H5T_NATIVE_LLONG,
        H5T_NATIVE_ULLONG, H5T_IEEE_F32BE, H5T_IEEE_F32LE, H5T_IEEE_F64BE,
        H5T_IEEE_F64LE, H5T_NATIVE_FLOAT, H5T_NATIVE_DOUBLE,
        H5T_NATIVE_LDOUBLE, H5T_STRING</emphasis> or <emphasis
        role="bold">H5T_COMPOUND.</emphasis></para>

        <para>Returns the string representation upon success, otherwise
        NULL.</para>
      </sect2>

      <sect2>
        <title>getFormatNameString</title>

        <para>char* <emphasis role="bold">getFormatNameString</emphasis>(hid_t
        type)</para>

        <para>Translates the HDF5 type <emphasis role="bold">type</emphasis>
        to a HL-HDF string representation of the datatype. The returned string
        can be one of <emphasis role="bold">char, schar, uchar, short, ushort,
        int, uint, long, ulong, llong, ullong, float, double, hsize, hssize,
        herr, hbool, string</emphasis> or <emphasis
        role="bold">compound.</emphasis></para>

        <para>Returns the string representation upon success, otherwise
        NULL.</para>
      </sect2>

      <sect2>
        <title>getStringPadName</title>

        <para>char* <emphasis role="bold">getStringPadName</emphasis>(hid_t
        type)</para>

        <para>Returns a string representation of the type <emphasis
        role="bold">type</emphasis>'s padding. The returned string can be one
        of <emphasis role="bold">H5T_STR_NULLTERM, H5T_STR_NULLPAD,
        H5T_STR_SPACEPAD</emphasis> or <emphasis role="bold">ILLEGAL
        STRPAD</emphasis>.</para>

        <para>Returns the string representation upon success, otherwise
        NULL.</para>
      </sect2>

      <sect2>
        <title>getStringCsetName</title>

        <para>char* <emphasis role="bold">getStringCsetName</emphasis>(hid_t
        type)</para>

        <para>Returns a string representation of the type <emphasis
        role="bold">type</emphasis>'s character set. The returned string can
        be one of <emphasis role="bold">H5T_CSET_ASCII</emphasis> or <emphasis
        role="bold">UNKNOWN CHARACTER SET</emphasis>.</para>

        <para>Returns the string representation upon success, otherwise
        NULL.</para>
      </sect2>

      <sect2>
        <title>getStringCtypeName</title>

        <para>char* <emphasis role="bold">getStringCtypeName</emphasis>(hid_t
        type)</para>

        <para>Returns a string representation of the type <emphasis
        role="bold">type</emphasis>'s character type. The returned string can
        be one of <emphasis role="bold">H5T_C_S1</emphasis>, <emphasis
        role="bold">H5T_FORTRAN_S1</emphasis> or <emphasis role="bold">UNKNOWN
        CHARACTER TYPE</emphasis>.</para>

        <para>Returns the string representation upon success, otherwise
        NULL.</para>
      </sect2>

      <sect2>
        <title>whatSizeIsHdfFormat</title>

        <para>int <emphasis role="bold">whatSizeIsHdfFormat</emphasis>(const
        char* format)</para>

        <para>Calculates the size in bytes that the specified type
        takes.</para>

        <para><emphasis role="bold">format</emphasis> can be one of <emphasis
        role="bold">char</emphasis>, <emphasis role="bold">schar</emphasis>,
        <emphasis role="bold">uchar</emphasis>, <emphasis
        role="bold">short</emphasis>, <emphasis role="bold">ushort</emphasis>,
        <emphasis role="bold">int</emphasis>, <emphasis
        role="bold">uint</emphasis>, <emphasis role="bold">long</emphasis>,
        <emphasis role="bold">ulong</emphasis>, <emphasis
        role="bold">llong</emphasis>, <emphasis role="bold">ullong</emphasis>,
        <emphasis role="bold">float</emphasis>, <emphasis
        role="bold">double</emphasis>, <emphasis role="bold">hsize</emphasis>,
        <emphasis role="bold">hssize</emphasis>, <emphasis
        role="bold">herr</emphasis> or <emphasis
        role="bold">hbool</emphasis>.</para>

        <para>Returns the size in bytes if successful or -1 in case of
        failure.</para>
      </sect2>

      <sect2>
        <title>isFormatSupported</title>

        <para>int <emphasis role="bold">isFormatSupported</emphasis>(const
        char* format)</para>

        <para>Checks wether the string type <emphasis
        role="bold">format</emphasis> is recognized.</para>

        <para><emphasis role="bold">format</emphasis> can be one of <emphasis
        role="bold">char</emphasis>, <emphasis role="bold">schar</emphasis>,
        <emphasis role="bold">uchar</emphasis>, <emphasis
        role="bold">short</emphasis>, <emphasis role="bold">ushort</emphasis>,
        <emphasis role="bold">int</emphasis>, <emphasis
        role="bold">uint</emphasis>, <emphasis role="bold">long</emphasis>,
        <emphasis role="bold">ulong</emphasis>, <emphasis
        role="bold">llong</emphasis>, <emphasis role="bold">ullong</emphasis>,
        <emphasis role="bold">float</emphasis>, <emphasis
        role="bold">double</emphasis>, <emphasis role="bold">hsize</emphasis>,
        <emphasis role="bold">hssize</emphasis>, <emphasis
        role="bold">herr</emphasis> or <emphasis
        role="bold">hbool</emphasis>.</para>

        <para>Returns 1 if the <emphasis role="bold">format</emphasis> is
        supported, otherwise 0.</para>
      </sect2>

      <sect2>
        <title>newHL_Node</title>

        <para>HL_Node* <emphasis role="bold">newHL_Node</emphasis>(const char*
        name)</para>

        <para>Defines a new, empty node of undefined type.</para>

        <para><emphasis role="bold">name</emphasis> is a string used to
        identify the node.</para>

        <para>Returns the node if successful or <emphasis
        role="bold">NULL</emphasis> upon failure.</para>
      </sect2>

      <sect2>
        <title>newHL_NodeList</title>

        <para>HL_NodeList* <emphasis
        role="bold">newHL_NodeList</emphasis>()</para>

        <para>Creates an empty HL node list which can be filled with an
        arbitrary number of nodes.</para>

        <para>Returns the node list if successful or <emphasis
        role="bold">NULL</emphasis> upon failure.</para>
      </sect2>

      <sect2>
        <title>freeHL_Node</title>

        <para>void <emphasis role="bold">freeHL_Node</emphasis>(HL_Node*
        node)</para>

        <para>Frees a node from memory. The node is given as the only
        argument.</para>

        <para>Returns nothing.</para>
      </sect2>

      <sect2>
        <title>freeHL_NodeList</title>

        <para>void <emphasis
        role="bold">freeHL_NodeList</emphasis>(HL_NodeList* nodelist)</para>

        <para>Frees a complete node list from memory, along with all the nodes
        contained in it. The node list is given as the only argument.</para>

        <para>Returns nothing.</para>
      </sect2>

      <sect2>
        <title>newHL_Group</title>

        <para>HL_Node* <emphasis role="bold">newHL_Group</emphasis>(const
        char* name)</para>

        <para>Creates an empty HL node of <emphasis
        role="bold">Group</emphasis> type.</para>

        <para><emphasis role="bold">name</emphasis> is a string used to
        identify the node.</para>

        <para>Returns the node if successful or <emphasis
        role="bold">NULL</emphasis> upon failure.</para>
      </sect2>

      <sect2>
        <title>newHL_Attribute</title>

        <para>HL_Node* <emphasis role="bold">newHL_Attribute</emphasis>(const
        char* name)</para>

        <para>Creates an empty HL node of <emphasis
        role="bold">Attribute</emphasis> type.</para>

        <para><emphasis role="bold">name</emphasis> is a string used to
        identify the node.</para>

        <para>Returns the node if successful or <emphasis
        role="bold">NULL</emphasis> upon failure.</para>
      </sect2>

      <sect2>
        <title>newHL_Reference</title>

        <para>HL_Node* <emphasis role="bold">newHL_Reference</emphasis>(const
        char* name)</para>

        <para>Creates an empty HL node of <emphasis
        role="bold">Reference</emphasis> type.</para>

        <para><emphasis role="bold">name</emphasis> is a string used to
        identify the node.</para>

        <para>Returns the node if successful or <emphasis
        role="bold">NULL</emphasis> upon failure.</para>
      </sect2>

      <sect2>
        <title>newHL_Dataset</title>

        <para>HL_Node* <emphasis role="bold">newHL_Dataset</emphasis>(const
        char* name)</para>

        <para>Creates an empty HL node of <emphasis
        role="bold">Dataset</emphasis> type.</para>

        <para><emphasis role="bold">name</emphasis> is a string used to
        identify the node.</para>

        <para>Returns the node if successful or <emphasis
        role="bold">NULL</emphasis> upon failure.</para>
      </sect2>

      <sect2>
        <title>newHL_Datatype</title>

        <para>HL_Node* <emphasis role="bold">newHL_Datatype</emphasis>(const
        char* name)</para>

        <para>Creates an empty HL node of <emphasis
        role="bold">Datatype</emphasis> type.</para>

        <para><emphasis role="bold">name</emphasis> is a string used to
        identify the node.</para>

        <para>Returns the node if successful or <emphasis
        role="bold">NULL</emphasis> upon failure.</para>
      </sect2>

      <sect2>
        <title>newHL_CompoundTypeAttribute</title>

        <para>HL_CompoundTypeAttribute* <emphasis
        role="bold">newHL_CompoundTypeAttribute</emphasis>(char*attrname,size_t
        offset,char* format,int ndims,size_t* dims)</para>

        <para>Creates a compound <emphasis role="bold">Attribute</emphasis>
        node. This function is used to read nodes which are not simple atomic
        types. It is designed to hold the <emphasis
        role="bold">Attribute</emphasis> in the form of <emphasis
        role="bold">unsigned char*</emphasis> along with information on how to
        interpret its contents.</para>

        <para><emphasis role="bold">attrname</emphasis>: String containing the
        <emphasis role="bold">Attribute</emphasis>'s name.</para>

        <para><emphasis role="bold">offset</emphasis>: The byte offset in the
        data where the <emphasis role="bold">Attribute</emphasis>'s value
        starts.</para>

        <para><emphasis role="bold">format</emphasis>: An atomic type, in
        character format, describing the <emphasis
        role="bold">Attribute</emphasis>, for example "<emphasis
        role="bold">short</emphasis>", or "<emphasis
        role="bold">double</emphasis>".</para>

        <para><emphasis role="bold">ndims</emphasis>: Number of dimensions in
        the <emphasis role="bold">Attribute</emphasis>'s array.</para>

        <para><emphasis role="bold">dims</emphasis>: The dimensions of each of
        <emphasis role="bold">ndims</emphasis>.</para>

        <para>Returns the compound node if successful or <emphasis
        role="bold">NULL</emphasis> upon failure.</para>
      </sect2>

      <sect2>
        <title>newHL_CompoundTypeDescription</title>

        <para>HL_CompoundTypeDescription* <emphasis
        role="bold">newHL_CompoundTypeDescription</emphasis>()</para>

        <para>Creates a list containing <emphasis
        role="bold">HL_CompoundTypeAttribute</emphasis>s.</para>

        <para>Returns the compound type list if successful or <emphasis
        role="bold">NULL</emphasis> upon failure.</para>
      </sect2>

      <sect2>
        <title>freeHL_CompoundTypeAttribute</title>

        <para>void <emphasis
        role="bold">freeHL_CompoundTypeAttribute</emphasis>(HL_CompoundTypeAttribute*
        attr)</para>

        <para>Frees a given compound type attribute from memory. The only
        argument is the <emphasis
        role="bold">HL_CompoundTypeAttribute</emphasis> to be freed.</para>

        <para>Returns nothing.</para>
      </sect2>

      <sect2>
        <title>freeHL_CompoundTypeDescription</title>

        <para>void <emphasis
        role="bold">freeHL_CompoundTypeDescription</emphasis>(HL_CompoundTypeDescription*
        typelist)</para>

        <para>Frees the compound type list, along with all its members, from
        memory. The only argument is the <emphasis
        role="bold">HL_CompoundTypeDescription</emphasis> to be freed.</para>

        <para>Returns nothing.</para>
      </sect2>

      <sect2>
        <title>addNode</title>

        <para>int <emphasis role="bold">addNode</emphasis>(HL_NodeList*
        nodelist, HL_Node* node)</para>

        <para>Appends a node to (the end of) a node list.</para>

        <para><emphasis role="bold">Note:</emphasis> If this operation is
        successful the responsibility for releasing the memory of the node
        <emphasis role="bold">node </emphasis>is taken by the nodelist, so do
        not release the <emphasis role="bold">node</emphasis>
        afterwards.</para>

        <para><emphasis role="bold">nodelist</emphasis>: The node list.</para>

        <para><emphasis role="bold">node</emphasis>: The node to append to
        <emphasis role="bold">nodelist</emphasis>.</para>

        <para>Returns 1 if successful and 0 otherwise.</para>
      </sect2>

      <sect2>
        <title>getNode</title>

        <para>HL_Node* <emphasis role="bold">getNode</emphasis>(HL_NodeList*
        nodelist,const char* nodeName)</para>

        <para>Provides a reference to a node from a node list.</para>

        <para><emphasis role="bold">Note:</emphasis> A reference to the node
        is returned, so do not release the <emphasis
        role="bold">node</emphasis> when finished with the node.</para>

        <para><emphasis role="bold">nodelist</emphasis>: The node list.</para>

        <para><emphasis role="bold">nodeName</emphasis>: A string identifying
        the node to extract.</para>

        <para>Returns (a reference to) the node if it is found, and <emphasis
        role="bold">NULL</emphasis> if not.</para>
      </sect2>

      <sect2>
        <title>setScalarValue</title>

        <para>int <emphasis role="bold">setScalarValue</emphasis>(HL_Node*
        node,size_t sz,unsigned char* value,const char* fmt,hid_t
        typid)</para>

        <para>Writes a scalar value to a node. Scalar values are individual
        atomic words.</para>

        <para><emphasis role="bold">node</emphasis>: The node in which to
        write the value.</para>

        <para><emphasis role="bold">sz</emphasis>: Size of the data
        type.</para>

        <para><emphasis role="bold">value</emphasis>: The value to
        write.</para>

        <para><emphasis role="bold">fmt</emphasis>: String representation of
        the data format, for example "<emphasis role="bold">short</emphasis>",
        "<emphasis role="bold">signed int</emphasis>" or "<emphasis
        role="bold">double</emphasis>".</para>

        <para><emphasis role="bold">typid</emphasis>: Reference to used data
        type. Must be set manually if using a compound data type, otherwise
        set it to -1.</para>

        <para>Returns 1 if successful and 0 otherwise.</para>
      </sect2>

      <sect2>
        <title>setArrayValue</title>

        <para>int <emphasis role="bold">setArrayValue</emphasis>(HL_Node*
        node,size_t sz,int ndims,hsize_t* dims,unsigned char* value,const
        char* fmt,hid_t typid)</para>

        <para>Writes an array to a node.</para>

        <para><emphasis role="bold">node</emphasis>: The node in which to
        write the array.</para>

        <para><emphasis role="bold">sz</emphasis>: Size of the data
        type.</para>

        <para><emphasis role="bold">ndims</emphasis>: The number of dimensions
        of the array, which may range from 0 to 4.</para>

        <para><emphasis role="bold">dims</emphasis>: The dimensions of each of
        <emphasis role="bold">ndims</emphasis>.</para>

        <para><emphasis role="bold">value</emphasis>: The array to
        write.</para>

        <para><emphasis role="bold">fmt</emphasis>: String representation of
        the data format.</para>

        <para><emphasis role="bold">typid</emphasis>: Reference to used data
        type. Must be set manually if using a compound data type, otherwise
        set it to -1.</para>

        <para>Returns 1 if successful and 0 otherwise.</para>
      </sect2>

      <sect2>
        <title>extractParentChildName</title>

        <para>int <emphasis
        role="bold">extractParentChildName</emphasis>(HL_Node* node, char*
        parent, char* child)</para>

        <para>Seperates the last node (the child) in a node name consisting of
        several nodes (the parent). For example, for a node name given as
        <emphasis role="bold">/group1/group2/group3</emphasis>, this function
        will set <emphasis role="bold">/group1/group2</emphasis> as the parent
        and <emphasis role="bold">group3</emphasis> as the child.</para>

        <para><emphasis role="bold">node</emphasis>: The node under
        scrutiny.</para>

        <para><emphasis role="bold">parent</emphasis>: A string to hold the
        parent's node name.</para>

        <para><emphasis role="bold">child</emphasis>: A string to hold the
        child's node name.</para>

        <para>Returns 1 if successful and 0 otherwise.</para>
      </sect2>

      <sect2>
        <title>commitDatatype</title>

        <para>int <emphasis role="bold">commitDatatype</emphasis>(HL_Node*
        node,hid_t testStruct_hid)</para>

        <para>If a compound type has been created and there is a wish to have
        this node "named", then use this function for marking this node to be
        committed. See the HDF5 documentation for a more detailed description
        on what "committed" means.</para>

        <para><emphasis role="bold">node</emphasis>: A <emphasis
        role="bold">Datatype</emphasis> node to mark.</para>

        <para><emphasis role="bold">testStruct_hid</emphasis>: The HDF5
        <emphasis role="bold">hid_t</emphasis> reference to the
        datatype.</para>

        <para>Returns 1 if successful and 0 otherwise.</para>
      </sect2>

      <sect2>
        <title>scanNodeList</title>

        <para>void <emphasis role="bold">scanNodeList</emphasis>(HL_NodeList*
        nodelist)</para>

        <para>Prints the names in a node list to the terminal. The only
        argument is the node list.</para>

        <para>Returns nothing.</para>
      </sect2>

      <sect2>
        <title>findCompoundTypeDescription</title>

        <para>HL_CompoundTypeDescription* <emphasis
        role="bold">findCompoundTypeDescription</emphasis>(HL_NodeList*
        nodelist, unsigned long objno0,unsigned long objno1)</para>

        <para>Searches a node list (<emphasis role="bold">nodelist</emphasis>)
        for all nodes with are identified by values <emphasis
        role="bold">objno0</emphasis> or <emphasis
        role="bold">objno1</emphasis>.</para>

        <para>Use this function to inquire wether an attribute's or dataset's
        type is "committed".</para>

        <para>Returns an <emphasis
        role="bold">HL_CompoundTypeDescription</emphasis> list if any nodes
        are found, otherwise <emphasis role="bold">NULL</emphasis>.</para>
      </sect2>

      <sect2>
        <title>scanCompoundTypeDescription</title>

        <para>void <emphasis
        role="bold">scanCompoundTypeDescription</emphasis>(HL_CompoundTypeDescription*
        typelist)</para>

        <para>Prints to the terminal the names of all nodes in the <emphasis
        role="bold">typelist</emphasis> list of compound nodes.</para>

        <para>Returns nothing.</para>
      </sect2>
    </sect1>

    <sect1>
      <title>Display functions</title>
      <para>N/A</para>
    </sect1>

    <sect1>
      <title>Debug functions</title>
      <para>A new improved debug functionality has beed added to the HL-HDF package. This allows
      the user to route error messages from both the HL-HDF software and the HDF5 software to
      your own functions.</para>

      <sect2>
        <title>HL_InitializeDebugger</title>
        <para>void <emphasis role="bold">HL_InitializeDebugger</emphasis>()</para>
        <para>This method will invoke the default settings for how the log messages should be handled, it is
        essential that this method is called, as it is now, this will actually be handled by initHlHdf() which
        is a mandatory call for all applications using HL-HDF</para>
      </sect2>

      <sect2>
        <title>HL_setDebugLevel</title>
        <para>void <emphasis role="bold">HL_setDebugLevel</emphasis>(lvl)</para>
        <para>This will set the debug level to be used when running the application,
        if lvl has been set to for example HLHDF_ERROR, only messages with level that is
        greater or equal will be produced.</para>
        <para>Valid debug levels are: <emphasis role="bold">HLHDF_SPEWDEBUG</emphasis>, <emphasis role="bold">HLHDF_DEBUG</emphasis>, 
        <emphasis role="bold">HLHDF_DEPRECATED</emphasis>, <emphasis role="bold">HLHDF_INFO</emphasis>, 
        <emphasis role="bold">HLHDF_WARNING</emphasis>, <emphasis role="bold">HLHDF_ERROR</emphasis>, 
        <emphasis role="bold">HLHDF_CRITICAL</emphasis> and <emphasis role="bold">HLHDF_SILENT</emphasis>. </para>

        <para><emphasis role="bold">HLHDF_SILENT</emphasis> turns off all debug output from HL-HDF.</para>
      </sect2>
      <sect2>
        <title>HL_setDebugFunction</title>
        <para>void <emphasis role="bold">HL_setDebugFunction</emphasis>(void (*dbgfun)(char* filename, int lineno, HL_Debug lvl, const char* fmt, ...))</para>

        <para>This function lets the user reroute the error messages sent from HL-HDF to a custom implemented debug writer, the
        argument taken is a function pointer</para>
      </sect2>
      <sect2>
        <title>HL_setHdf5ErrorFunction</title>
        <para>void <emphasis role="bold">HL_setHdf5ErrorFunction</emphasis>(void (*hdf5fun)(int n, H5E_error_t* val))</para>
        <para>This function lets the user reroute the error messages sent from the HDF5 library to a custom implemented debug writer,
        the argument taken is a function pointer</para>
      </sect2>
      <sect2>
        <title>HL_disableHdf5ErrorReporting</title>
        <para>void <emphasis role="bold">HL_disableHdf5ErrorReporting</emphasis>()</para>
        <para>This function will disable all error messages sent from the HDF5 library.</para>
      </sect2>
      <sect2>
        <title>HL_enableHdf5ErrorReporting</title>
        <para>void <emphasis role="bold">HL_enableHdf5ErrorReporting</emphasis>()</para>
        <para>This function will enable so that error messages sent from the HDF5 library is forwarded to the
        correct writer</para>
      </sect2>
    </sect1>

    <sect1>
      <title>Read functions</title>

      <sect2>
        <title>readHL_NodeListFrom</title>

        <para>HL_NodeList* <emphasis
        role="bold">readHL_NodeListFrom</emphasis>(const char* filename, const
        char* fromPath)</para>

        <para>Recursively reads the HDF5 file <emphasis
        role="bold">filename</emphasis> from the group <emphasis
        role="bold">fromPath</emphasis> and builds a list of nodes with
        corresponding names. I.e. no data will be read at this step, just the
        nodetypes and names will be determined.</para>

        <para>Returns an <emphasis role="bold">HL_NodeList</emphasis> pointer
        upon success, otherwise NULL.</para>
      </sect2>

      <sect2>
        <title>readHL_NodeList</title>

        <para>HL_NodeList* <emphasis
        role="bold">readHL_NodeList</emphasis>(const char* filename)</para>

        <para>Recursively read the HDF5 file <emphasis
        role="bold">filename</emphasis> from the root group and builds a list
        of nodes with corresponding names. I.e. no data will be read at this
        step, just the nodetypes and names will be determined.</para>

        <para>Returns an <emphasis role="bold">HL_NodeList</emphasis> pointer
        upon success, otherwise NULL.</para>
      </sect2>

      <sect2>
        <title>selectNode</title>

        <para>int <emphasis role="bold">selectNode</emphasis>(HL_NodeList*
        nodelist, const char* name)</para>

        <para>Marks the node with name <emphasis role="bold">name</emphasis>
        in the <emphasis role="bold">nodelist</emphasis> for retrival.</para>

        <para>Returns 1 upon success, otherwise 0.</para>
      </sect2>

      <sect2>
        <title>selectAllNodes</title>

        <para>int <emphasis role="bold">selectAllNodes</emphasis>(HL_NodeList*
        nodelist)</para>

        <para>Marks all nodes in the <emphasis role="bold">nodelist</emphasis>
        for retrival.</para>

        <para>Returns 1 upon success, otherwise 0.</para>
      </sect2>

      <sect2>
        <title>fetchMarkedNodes</title>

        <para>int <emphasis
        role="bold">fetchMarkedNodes</emphasis>(HL_NodeList* nodelist)</para>

        <para>Reads all nodes in the <emphasis role="bold">nodelist</emphasis>
        that has been marked for retrival.</para>

        <para>Returns 1 upon success, otherwise 0.</para>
      </sect2>

      <sect2>
        <title>fillAttributeNode</title>

        <para>int <emphasis role="bold">fillAttributeNode</emphasis>(hid_t
        file_id, HL_Node* node)</para>

        <para>Fills the attribute node <emphasis role="bold">node</emphasis>
        with data and dimensions from the file referenced by <emphasis
        role="bold">file_id</emphasis>.</para>

        <para>Returns 1 upon success, otherwise 0.</para>
      </sect2>

      <sect2>
        <title>fillReferenceNode</title>

        <para>int <emphasis role="bold">fillReferenceNode</emphasis>(hid_t
        file_id, HL_Node* node)</para>

        <para>Fills the reference node <emphasis role="bold">node</emphasis>
        with data from the file referenced by <emphasis
        role="bold">file_id</emphasis>. The data field in the <emphasis
        role="bold">node</emphasis> will be filled with a string that
        specifies the name of the referenced <emphasis
        role="bold">node</emphasis>.</para>

        <para>Returns 1 upon success, otherwise 0.</para>
      </sect2>

      <sect2>
        <title>fillDatasetNode</title>

        <para>int <emphasis role="bold">fillDatasetNode</emphasis>(hid_t
        file_id, HL_Node* node)</para>

        <para>Fills the dataset node <emphasis role="bold">node</emphasis>
        with data and dimensions from the file referenced by <emphasis
        role="bold">file_id</emphasis>.</para>

        <para>Returns 1 upon success, otherwise 0.</para>
      </sect2>

      <sect2>
        <title>fillGroupNode</title>

        <para>int <emphasis role="bold">fillGroupNode</emphasis>(hid_t
        file_id, HL_Node* node)</para>

        <para>Fills the group node <emphasis role="bold">node</emphasis> with
        data from the file referenced by <emphasis
        role="bold">file_id</emphasis>.</para>

        <para>Returns 1 upon success, otherwise 0.</para>
      </sect2>

      <sect2>
        <title>fillTypeNode</title>

        <para>int <emphasis role="bold">fillTypeNode</emphasis>(hid_t file_id,
        HL_Node* node)</para>

        <para>Fills the type node <emphasis role="bold">node</emphasis> with
        data from the file referenced by <emphasis
        role="bold">file_id</emphasis>.</para>

        <para>Returns 1 upon success, otherwise 0.</para>
      </sect2>

      <sect2>
        <title>fillNodeWithData</title>

        <para>int <emphasis role="bold">fillNodeWithData</emphasis>(hid_t
        file_id, HL_Node* node)</para>

        <para>Fills the node <emphasis role="bold">node</emphasis> with data
        from the file referenced by <emphasis
        role="bold">file_id</emphasis>.</para>

        <para>Returns 1 upon success, otherwise 0.</para>
      </sect2>

      <sect2>
        <title>buildTypeDescriptionFromTypeHid</title>

        <para>HL_CompoundTypeDescription* <emphasis
        role="bold">buildTypeDescriptionFromTypeHid</emphasis>(hid_t
        type_id)</para>

        <para>Builds a compound type description from the type <emphasis
        role="bold">type_id</emphasis> reference.</para>

        <para>Returns a <emphasis
        role="bold">HL_CompoundTypeDescription</emphasis> pointer upon
        success, otherwise NULL.</para>
      </sect2>

      <sect2>
        <title>locateNameForReference</title>

        <para>char* <emphasis
        role="bold">locateNameForReference</emphasis>(hid_t file_id,
        hobj_ref_t* ref)</para>

        <para>This is a helper function for locating the name of an object
        that is referenced by <emphasis role="bold">ref</emphasis> in the file
        <emphasis role="bold">file_id</emphasis>.</para>

        <para>Returns a pointer to a string upon success, otherwise
        NULL.</para>
      </sect2>
    </sect1>

    <sect1>
      <title>Write functions</title>

      <sect2>
        <title>commitType</title>

        <para>herr_t <emphasis role="bold">commitType</emphasis>(hid_t loc_id,
        const char* name, hid_t type_id)</para>

        <para>Commits a datatype. See the HDF5 documentation for more detailed
        descriptions on what "committed" means.</para>

        <para><emphasis role="bold">loc_id</emphasis>: Where should the
        datatype be placed.</para>

        <para><emphasis role="bold">name</emphasis>: What should the datatype
        be called.</para>

        <para><emphasis role="bold">type_id</emphasis>: The <emphasis
        role="bold">hid_t</emphasis> reference to the datatype.</para>

        <para>Returns a negative value upon failure, otherwise the operation
        was successful.</para>
      </sect2>

      <sect2>
        <title>createStringType</title>

        <para>hid_t <emphasis role="bold">createStringType</emphasis>(size_t
        length)</para>

        <para>Creates a HDF5 string type of length <emphasis
        role="bold">length</emphasis>.</para>

        <para>Returns a negative value upon failure, otherwise a <emphasis
        role="bold">hid_t</emphasis> reference to the datatype.</para>
      </sect2>

      <sect2>
        <title>setTypeSize</title>

        <para>herr_t <emphasis role="bold">setTypeSize</emphasis>(hid_t
        type_id,size_t theSize)</para>

        <para>Changes the size of the datatype referenced by <emphasis
        role="bold">type_id</emphasis> to the size <emphasis
        role="bold">theSize</emphasis>.</para>

        <para>Returns a negative value upon failure, otherwise the operation
        was successful.</para>
      </sect2>

      <sect2>
        <title>closeType</title>

        <para>herr_t <emphasis role="bold">closeType</emphasis>(hid_t
        type_id)</para>

        <para>Closes the datatype referenced by <emphasis
        role="bold">type_id</emphasis>.</para>

        <para>Returns a negative value upon failure, otherwise the operation
        was successful.</para>
      </sect2>

      <sect2>
        <title>writeScalarDataAttribute</title>

        <para>herr_t <emphasis
        role="bold">writeScalarDataAttribute</emphasis>(hid_t loc_id, hid_t
        type_id, const char* name, void* buf)</para>

        <para>Writes a scalar value to an HDF5 file.</para>

        <para><emphasis role="bold">loc_id</emphasis>: The group or dataset
        the attribute should be written to.</para>

        <para><emphasis role="bold">type_id</emphasis>: The datatype of the
        attribute.</para>

        <para><emphasis role="bold">name</emphasis>: The name that should be
        used for the attribute.</para>

        <para><emphasis role="bold">buf</emphasis>: The data that should be
        written. Returns 0 upon success, otherwise -1.</para>
      </sect2>

      <sect2>
        <title>writeScalarDataAttribute_fmt</title>

        <para>herr_t <emphasis
        role="bold">writeScalarDataAttribute_fmt</emphasis>(hid_t loc_id,
        const char* fmt, const char* name, void* buf)</para>

        <para>Writes a scalar value to an HDF5 file.</para>

        <para><emphasis role="bold">loc_id</emphasis>: The group or dataset
        the attribute should be written to.</para>

        <para><emphasis role="bold">fmt</emphasis>: A string describing the
        format of the datatype, e.g. <emphasis role="bold">char</emphasis>,
        <emphasis role="bold">short</emphasis>, ...</para>

        <para><emphasis role="bold">name</emphasis>: The name that should be
        used for the attribute.</para>

        <para><emphasis role="bold">buf</emphasis>: The data that should be
        written.</para>

        <para>Returns 0 upon success, otherwise -1.</para>
      </sect2>

      <sect2>
        <title>writeSimpleDataAttribute</title>

        <para>herr_t <emphasis
        role="bold">writeSimpleDataAttribute</emphasis>(hid_t loc_id, hid_t
        type_id, const char* name, int ndims, hsize_t* dims, void* buf)</para>

        <para>Writes a simple data attribute value to an HDF5 file.</para>

        <para><emphasis role="bold">loc_id</emphasis>: The group or dataset
        the attribute should be written to.</para>

        <para><emphasis role="bold">type_id</emphasis>: The datatype of the
        attribute.</para>

        <para><emphasis role="bold">name</emphasis>: The name that should be
        used for the attribute.</para>

        <para><emphasis role="bold">ndims</emphasis>: The rank of the data to
        be written, between 0-4.</para>

        <para><emphasis role="bold">dims</emphasis>: The dimensions of the
        data, a pointer to <emphasis role="bold">ndims</emphasis> number of
        <emphasis role="bold">hsize_t</emphasis> values.</para>

        <para><emphasis role="bold">buf</emphasis>: The data that should be
        written.</para>

        <para>Returns 0 upon success, otherwise -1.</para>
      </sect2>

      <sect2>
        <title>writeSimpleDataAttribute_fmt</title>

        <para>herr_t <emphasis
        role="bold">writeSimpleDataAttribute_fmt</emphasis>(hid_t loc_id,
        const char* fmt, const char* name, int ndims, hsize_t* dims, void*
        buf)</para>

        <para>Writes a simple data attribute value to an HDF5 file.</para>

        <para><emphasis role="bold">loc_id</emphasis>: The group or dataset
        the attribute should be written to.</para>

        <para><emphasis role="bold">fmt</emphasis>: A string describing the
        format of the datatype, e.g. <emphasis role="bold">char</emphasis>,
        <emphasis role="bold">short</emphasis>, ...</para>

        <para><emphasis role="bold">name</emphasis>: The name that should be
        used for the attribute.</para>

        <para><emphasis role="bold">ndims</emphasis>: The rank of the data to
        be written, between 0-4.</para>

        <para><emphasis role="bold">dims</emphasis>: The dimensions of the
        data, a pointer to <emphasis role="bold">ndims</emphasis> number of
        <emphasis role="bold">hsize_t</emphasis> values.</para>

        <para><emphasis role="bold">buf</emphasis>: The data that should be
        written.</para>

        <para>Returns 0 upon success, otherwise -1.</para>
      </sect2>

      <sect2>
        <title>createSimpleDataset</title>

        <para>hid_t <emphasis role="bold">createSimpleDataset</emphasis>(hid_t
        loc_id, hid_t type_id, const char* name, int ndims, hsize_t* dims,
        void* buf, int compress)</para>

        <para>Creates a dataset in an HDF5 file.</para>

        <para><emphasis role="bold">loc_id</emphasis>: The group the dataset
        should be created in.</para>

        <para><emphasis role="bold">type_id</emphasis>: The datatype of the
        dataset.</para>

        <para><emphasis role="bold">name</emphasis>: The name that should be
        used for the dataset.</para>

        <para><emphasis role="bold">ndims</emphasis>: The rank of the data to
        be written.</para>

        <para><emphasis role="bold">dims</emphasis>: The dimensions of the
        data, a pointer to <emphasis role="bold">ndims</emphasis> number of
        <emphasis role="bold">hsize_t</emphasis> values.</para>

        <para><emphasis role="bold">buf</emphasis>: The data to be written in
        the dataset, if NULL, an empty dataset will be created.</para>

        <para><emphasis role="bold">compress</emphasis>: The compression level
        on the dataset, betwen 0-9 where 0 is no compression and 9 is highest
        compression.</para>

        <para>Returns -1 on failure, otherwise a <emphasis
        role="bold">hid_t</emphasis> reference to the dataset.</para>
      </sect2>

      <sect2>
        <title>createSimpleDataset_fmt</title>

        <para>hid_t <emphasis role="bold">createSimpleDataset</emphasis>(hid_t
        loc_id, const char* fmt, const char* name, int ndims, hsize_t* dims,
        void* buf, int compress)</para>

        <para>Creates a dataset in an HDF5 file.</para>

        <para><emphasis role="bold">oc_id</emphasis>: The group the dataset
        should be created in.</para>

        <para><emphasis role="bold">fmt</emphasis>: A string describing the
        format of the datatype, e.g. <emphasis role="bold">char</emphasis>,
        <emphasis role="bold">short</emphasis>, ...</para>

        <para><emphasis role="bold">name</emphasis>: The name that should be
        used for the dataset.</para>

        <para><emphasis role="bold">ndims</emphasis>: The rank of the data to
        be written.</para>

        <para><emphasis role="bold">dims</emphasis>: The dimensions of the
        data, a pointer to <emphasis role="bold">ndims</emphasis> number of
        <emphasis role="bold">hsize_t</emphasis> values.</para>

        <para><emphasis role="bold">buf</emphasis>: The data to be written in
        the dataset, if NULL, an empty dataset will be created. <emphasis
        role="bold">compress</emphasis>: The compression level on the dataset,
        betwen 0-9 where 0 is no compression and 9 is highest
        compression.</para>

        <para>Returns -1 on failure, otherwise a <emphasis
        role="bold">hid_t</emphasis> reference to the dataset.</para>
      </sect2>

      <sect2>
        <title>closeDataset</title>

        <para>herr_t <emphasis role="bold">closeDataset</emphasis>(hid_t
        loc_id)</para>

        <para>Closes the dataset referenced by <emphasis
        role="bold">loc_id</emphasis>.</para>

        <para>Returns a negative value upon failiure, otherwise the operation
        was successful.</para>
      </sect2>

      <sect2>
        <title>createCompoundType</title>

        <para>hid_t <emphasis role="bold">createCompoundType</emphasis>(size_t
        size)</para>

        <para>Creates a compound type with the size <emphasis
        role="bold">size</emphasis>.</para>

        <para>Returns a negative value upon failiure, otherwise a <emphasis
        role="bold">hid_t</emphasis> reference.</para>
      </sect2>

      <sect2>
        <title>addAttributeToCompoundType</title>

        <para>herr_t <emphasis
        role="bold">addAttributeToCompoundType</emphasis>(hid_t loc_id, const
        char* name, size_t offset,hid_t type_id)</para>

        <para>Adds an scalar attribute to a compound type.</para>

        <para><emphasis role="bold">loc_id</emphasis>: The type the attribute
        should be appended to,</para>

        <para><emphasis role="bold">name</emphasis>: The name of the
        attribute.</para>

        <para><emphasis role="bold">offset</emphasis>: At what offset in the
        data does this attribute begin.</para>

        <para><emphasis role="bold">type_id</emphasis>: The datatype of the
        attribute.</para>

        <para>Returns a negative value upon failure, otherwise the operation
        was successful.</para>
      </sect2>

      <sect2>
        <title>addAttributeToCompoundType_fmt</title>

        <para>herr_t <emphasis
        role="bold">addAttributeToCompoundType_fmt</emphasis>(hid_t loc_id,
        const char* name, size_t offset,const char* fmt)</para>

        <para>Adds an scalar attribute to a compound type.</para>

        <para><emphasis role="bold">loc_id</emphasis>: The type the attribute
        should be appended to.</para>

        <para><emphasis role="bold">name</emphasis>: The name of the
        attribute.</para>

        <para><emphasis role="bold">offset</emphasis>: At what offset in the
        data does this attribute begin.</para>

        <para><emphasis role="bold">fmt</emphasis>: A string describing the
        format of the datatype, e.g. <emphasis role="bold">char</emphasis>,
        <emphasis role="bold">short</emphasis>, ...</para>

        <para>Returns a negative value upon failure, otherwise the operation
        was successful.</para>
      </sect2>

      <sect2>
        <title>addArrayToCompoundType</title>

        <para>herr_t <emphasis
        role="bold">addArrayToCompoundType</emphasis>(hid_t loc_id, const
        char* name, size_t offset, int ndims,size_t* dims,hid_t type_id) Adds
        an array attribute to a compound type.</para>

        <para><emphasis role="bold">loc_id</emphasis>: The type the attribute
        should be appended to.</para>

        <para><emphasis role="bold">name</emphasis>: The name of the
        attribute.</para>

        <para><emphasis role="bold">offset</emphasis>: At what offset in the
        data does this attribute begin.</para>

        <para><emphasis role="bold">ndims</emphasis>: The rank of the data to
        be written, between 0-4.</para>

        <para><emphasis role="bold">dims</emphasis>: The dimensions of the
        data, a pointer to <emphasis role="bold">ndims</emphasis> number of
        <emphasis role="bold">hsize_t</emphasis> values.</para>

        <para><emphasis role="bold">type_id</emphasis>: The datatype of the
        attribute.</para>

        <para>Returns a negative value upon failiure, otherwise the operation
        was successful.</para>
      </sect2>

      <sect2>
        <title>addArrayToCompoundType_fmt</title>

        <para>herr_t <emphasis
        role="bold">addArrayToCompoundType_fmt</emphasis>(hid_t loc_id, const
        char* name, size_t offset, int ndims, size_t* dims, const char*
        fmt)</para>

        <para>Adds an array attribute to a compound type.</para>

        <para><emphasis role="bold">loc_id</emphasis>: The type the attribute
        should be appended to.</para>

        <para><emphasis role="bold">name</emphasis>: The name of the
        attribute.</para>

        <para><emphasis role="bold">offset</emphasis>: At what offset in the
        data does this attribute begin.</para>

        <para><emphasis role="bold">ndims</emphasis>: The rank of the data to
        be written, between 0-4.</para>

        <para><emphasis role="bold">dims</emphasis>: The dimensions of the
        data, a pointer to <emphasis role="bold">ndims</emphasis> number of
        <emphasis role="bold">hsize_t</emphasis> values.</para>

        <para><emphasis role="bold">fmt</emphasis>: A string describing the
        format of the datatype, e.g. <emphasis role="bold">char</emphasis>,
        <emphasis role="bold">short</emphasis>, ...</para>

        <para>Returns a negative value upon failiure, otherwise the operation
        was successful.</para>
      </sect2>

      <sect2>
        <title>createGroup</title>

        <para>hid_t <emphasis role="bold">createGroup</emphasis>(hid_t loc_id,
        const char* groupname,const char* comment)</para>

        <para>Creates a group in an HDF5 file.</para>

        <para><emphasis role="bold">loc_id</emphasis>: The group or file
        reference the group should be written to.</para>

        <para><emphasis role="bold">groupname</emphasis>: The name of the
        group to be written.</para>

        <para><emphasis role="bold">comment</emphasis>: A comment of the
        group, if NULL, no comment will be added to the group.</para>

        <para>Returns a negative value on failure, otherwise a <emphasis
        role="bold">hid_t</emphasis> reference.</para>
      </sect2>

      <sect2>
        <title>closeGroup</title>

        <para>herr_t <emphasis role="bold">closeGroup</emphasis>(hid_t
        loc_id)</para>

        <para>Closes a group referenced by <emphasis
        role="bold">loc_id</emphasis>.</para>

        <para>Returns a negative value upon failure, otherwise the operation
        was successful.</para>
      </sect2>

      <sect2>
        <title>createReference</title>

        <para>herr_t <emphasis role="bold">createReference</emphasis>(hid_t
        loc_id, hid_t file_id, const char* name, const char*
        targetname)</para>

        <para>Creates a reference from <emphasis role="bold">name</emphasis>
        in object <emphasis role="bold">loc_id</emphasis> to the object with
        the name <emphasis role="bold">targetname</emphasis> which must be a
        complete path in the file <emphasis role="bold">file_id</emphasis>.
        For example, to create a reference from <emphasis
        role="bold">PALETTE</emphasis> to the <emphasis
        role="bold">dataset</emphasis> /GRP/PALETTE one should write <emphasis
        role="bold">createReference(loc_id,file_id,"PALETTE","/GRP/PALETTE")</emphasis>.</para>

        <para><emphasis role="bold">loc_id</emphasis>: The object where the
        reference <emphasis role="bold">name</emphasis> should be
        created.</para>

        <para><emphasis role="bold">file_id</emphasis>: The file the reference
        should be created in.</para>

        <para><emphasis role="bold">name</emphasis>: The name of the reference
        to be created.</para>

        <para><emphasis role="bold">targetname</emphasis>: The referenced
        object, must be a complete path.</para>

        <para><emphasis role="bold">Note that the referenced object must
        always be created before creating a reference to it</emphasis>.</para>

        <para>Returns 0 upon success, otherwise -1</para>
      </sect2>

      <sect2>
        <title>doWriteHdf5Attribute</title>

        <para>int <emphasis role="bold">doWriteHdf5Attribute</emphasis>(hid_t
        rootGrp, HL_Node* parentNode, char* parentName, HL_Node* childNode,
        char* childName)</para>

        <para>Writes an <emphasis role="bold">HL_Node</emphasis> attribute to
        an HDF5 file.</para>

        <para><emphasis role="bold">rootGrp</emphasis>: The root group of the
        file.</para>

        <para><emphasis role="bold">parentNode</emphasis>: The parent node of
        the attribute to be written.</para>

        <para><emphasis role="bold">parentName</emphasis>: The name of the
        parent node.</para>

        <para><emphasis role="bold">childNode</emphasis>: The node to be
        written.</para>

        <para><emphasis role="bold">childName</emphasis>: The attribute's
        name.</para>

        <para>Returns 1 upon success, otherwise 0.</para>
      </sect2>

      <sect2>
        <title>doWriteHdf5Group</title>

        <para>int <emphasis role="bold">doWriteHdf5Group</emphasis>(hid_t
        rootGrp, HL_Node* parentNode, char* parentName, HL_Node* childNode,
        char* childName)</para>

        <para>Writes an <emphasis role="bold">HL_Node</emphasis> group to an
        HDF5 file.</para>

        <para><emphasis role="bold">rootGrp</emphasis>: The root group of the
        file.</para>

        <para><emphasis role="bold">parentNode</emphasis>: The parent node of
        the group to be written.</para>

        <para><emphasis role="bold">parentName</emphasis>: The name of the
        parent node.</para>

        <para><emphasis role="bold">childNode</emphasis>: The node to be
        written.</para>

        <para><emphasis role="bold">childName</emphasis>: The group's
        name.</para>

        <para>Returns 1 upon success, otherwise 0.</para>
      </sect2>

      <sect2>
        <title>doWriteHdf5Dataset</title>

        <para>int <emphasis role="bold">doWriteHdf5Dataset</emphasis>(hid_t
        rootGrp, HL_Node* parentNode, char* parentName, HL_Node* childNode,
        char* childName, int doCompress)</para>

        <para>Writes an <emphasis role="bold">HL_Node</emphasis> dataset to an
        HDF5 file.</para>

        <para><emphasis role="bold">rootGrp</emphasis>: The root group of the
        file.</para>

        <para><emphasis role="bold">parentNode</emphasis>: The parent node of
        the dataset to be written.</para>

        <para><emphasis role="bold">parentName</emphasis>: The name of the
        parent node.</para>

        <para><emphasis role="bold">childNode</emphasis>: The node to be
        written.</para>

        <para><emphasis role="bold">childName</emphasis>: The dataset's
        name.</para>

        <para><emphasis role="bold">doCompress</emphasis>: The compression
        level on the dataset, betwen 0-9 where 0 is no compression and 9 is
        highest compression.</para>

        <para>Returns 1 upon success, otherwise 0.</para>
      </sect2>

      <sect2>
        <title>doCommitHdf5Datatype</title>

        <para>int <emphasis role="bold">doCommitHdf5Datatype</emphasis>(hid_t
        loc_id, HL_Node* parentNode, char* parentName, HL_Node* childNode,
        char* childName)</para>

        <para>Creates a "committed" datatype in the HDF5 file.</para>

        <para><emphasis role="bold">rootGrp</emphasis>: The root group of the
        file.</para>

        <para><emphasis role="bold">parentNode</emphasis>: The parent node of
        the datatype to be written.</para>

        <para><emphasis role="bold">parentName</emphasis>: The name of the
        parent node.</para>

        <para><emphasis role="bold">childNode</emphasis>: The node to be
        written.</para>

        <para><emphasis role="bold">childName</emphasis>: The datatype's
        name.</para>

        <para>Returns 1 upon success, otherwise 0.</para>
      </sect2>

      <sect2>
        <title>writeHL_NodeList</title>

        <para>int <emphasis
        role="bold">writeHL_NodeList</emphasis>(HL_NodeList* nodelist,
        HL_FileCreationProperty* property, HL_Compression* compression)</para>

        <para><emphasis role="bold">nodelist</emphasis>: The nodelist to be
        written.</para>

        <para><emphasis role="bold">property</emphasis>: The properties to be
        used when writing the file</para>

        <para><emphasis role="bold">compression</emphasis>: The compression to
        be used when writing the file</para>
      </sect2>

      <sect2>
        <title>writeNodeList</title>

        <para>int <emphasis role="bold">writeNodeList</emphasis>(HL_NodeList*
        nodelist, int doCompress)</para>

        <para>Writes a nodelist in HDF5 format.</para>

        <para><emphasis role="bold">nodelist</emphasis>: The nodelist to be
        written.</para>

        <para><emphasis role="bold">doCompress</emphasis>: The compression
        level that should be used on the datasets, betwen 0-9 where 0 is no
        compression and 9 is highest compression.</para>

        <para>Returns 1 upon success, otherwise 0.</para>
      </sect2>
    </sect1>

    <sect1>
      <title>Update functions</title>

      <para>This functionality allows the user to append data to an already
      existing HDF5 file.</para>

      <para><emphasis role="bold">Note:</emphasis> Currently HDF5 does not
      support the possibility that the disk is full when writing a file which
      means that if one is unlucky the HDF5 file will be corrupt. To avoid
      this, estimate if it is likely that the file can be updated before
      attempting to update it.</para>

      <sect2>
        <title>doAppendHdf5Attribute</title>

        <para>int <emphasis role="bold">doAppendHdf5Attribute</emphasis>(hid_t
        file_id, HL_Node* parentNode, char* parentName, HL_Node* childNode,
        char* childName)</para>

        <para>Appends an "attribute" node to the data structure.</para>

        <para><emphasis role="bold">file_id</emphasis>: The file
        reference.</para>

        <para><emphasis role="bold">parentNode</emphasis>: The parent node of
        the datatype to be written.</para>

        <para><emphasis role="bold">parentName</emphasis>: The name of the
        parent node.</para>

        <para><emphasis role="bold">childNode</emphasis>: The node to be
        written.</para>

        <para><emphasis role="bold">childName</emphasis>: The datatype's
        name.</para>

        <para>Returns 1 upon success, otherwise 0.</para>
      </sect2>

      <sect2>
        <title>doAppendHdf5Group</title>

        <para>int <emphasis role="bold">doAppendHdf5Group</emphasis>(hid_t
        file_id, HL_Node* parentNode, char* parentName, HL_Node* childNode,
        char* childName)</para>

        <para>Appends a "group" node to the data structure.</para>

        <para><emphasis role="bold">file_id</emphasis>: The file
        reference.</para>

        <para><emphasis role="bold">parentNode</emphasis>: The parent node of
        the datatype to be written.</para>

        <para><emphasis role="bold">parentName</emphasis>: The name of the
        parent node.</para>

        <para><emphasis role="bold">childNode</emphasis>: The node to be
        written.</para>

        <para><emphasis role="bold">childName</emphasis>: The datatype's
        name.</para>

        <para>Returns 1 upon success, otherwise 0.</para>
      </sect2>

      <sect2>
        <title>doAppendHdf5Dataset</title>

        <para>int <emphasis role="bold">doAppendHdf5Dataset</emphasis>(hid_t
        file_id, HL_Node* parentNode, char* parentName, HL_Node* childNode,
        char* childName)</para>

        <para>Appends a "dataset" node to the data structure.</para>

        <para><emphasis role="bold">file_id</emphasis>: The file
        reference.</para>

        <para><emphasis role="bold">parentNode</emphasis>: The parent node of
        the datatype to be written.</para>

        <para><emphasis role="bold">parentName</emphasis>: The name of the
        parent node.</para>

        <para><emphasis role="bold">childNode</emphasis>: The node to be
        written.</para>

        <para><emphasis role="bold">childName</emphasis>: The datatype's
        name.</para>

        <para>Returns 1 upon success, otherwise 0.</para>
      </sect2>

      <sect2>
        <title>updateNodeList</title>

        <para>int <emphasis role="bold">updateNodeList</emphasis>(HL_NodeList*
        nodelist, int doCompress)</para>

        <para>Updates the nodelist by calling the appropriate update function
        for each newly created node in the nodelist.</para>

        <para><emphasis role="bold">nodelist</emphasis>: The nodelist to be
        updated</para>

        <para><emphasis role="bold">doCompress</emphasis>: The compression
        level that should be used on the datasets, betwen 0-9 where 0 is no
        compression and 9 is highest compression.</para>

        <para>Returns 1 upon success, otherwise 0.</para>
      </sect2>
    </sect1>

    <sect1>
      <title>Deprecated</title>

      <para>Several functions are deprecated and are only provided for
      backward compatibility with alpha versions of this software which are
      actually being used. Avoid using these functions, since they will
      probably be removed in a future release.</para>

      <sect2>
        <title>newGroup</title>

        <para>NameListGroup_t* <emphasis
        role="bold">newGroup</emphasis>(NameListGroup_t* parentGroup,const
        char* name)</para>

        <para>Creates a new group named <emphasis role="bold">name</emphasis>
        and attaches this group to the <emphasis
        role="bold">parentGroup</emphasis>. If the <emphasis
        role="bold">parentGroup</emphasis> is NULL, then the created group
        will be the root group.</para>

        <para>Returns the new group upon success or NULL upon failure.</para>
      </sect2>

      <sect2>
        <title>newDataset</title>

        <para>NameListDataset_t* <emphasis
        role="bold">newDataset</emphasis>(NameListGroup_t* parentGroup, const
        char* name)</para>

        <para>Creates a new dataset named <emphasis
        role="bold">name</emphasis> and attaches this dataset to the <emphasis
        role="bold">parentGroup</emphasis>.</para>

        <para>Returns the new dataset upon success or NULL upon
        failiure.</para>
      </sect2>

      <sect2>
        <title>newNameListType</title>

        <para>NameListType_t* <emphasis
        role="bold">newNameListType</emphasis>()</para>

        <para>Creates a new type object.</para>

        <para>Returns the allocated type upon success or NULL upon
        failure.</para>
      </sect2>

      <sect2>
        <title>newAttribute</title>

        <para>NameListAttribute_t* <emphasis
        role="bold">newAttribute</emphasis>(const char* name)</para>

        <para>Creates a new attribute with the name <emphasis
        role="bold">name</emphasis>, if <emphasis role="bold">name</emphasis>
        is NULL, then the attribute will be nameless.</para>

        <para>Returns the allocated attribute upon success or NULL upon
        failure.</para>
      </sect2>

      <sect2>
        <title>newCompoundAttribute</title>

        <para>CompoundAttributeDef_t* <emphasis
        role="bold">newCompoundAttribute</emphasis>(const char* name)</para>

        <para>Creates a new compound attribute definition with the name
        <emphasis role="bold">name</emphasis>, if <emphasis
        role="bold">name</emphasis> is NULL, then the attribute will be
        nameless.</para>

        <para>Returns the allocated compound attribute definition upon success
        or NULL upon failure.</para>
      </sect2>

      <sect2>
        <title>createCompoundFromType</title>

        <para>CompoundAttributeDef_t* <emphasis
        role="bold">createCompoundFromType</emphasis>(NameListType_t* inType,
        char* name)</para>

        <para>Translates an <emphasis role="bold">NameListType_t</emphasis>
        instance to a compound attribute definition instance and then gives
        the compound attribute definition the name <emphasis
        role="bold">name</emphasis>.</para>

        <para>Returns the allocated compound attribute definition upon success
        or NULL upon failure.</para>
      </sect2>

      <sect2>
        <title>addCompoundAttributeToType</title>

        <para>herr_t <emphasis
        role="bold">addCompoundAttributeToType</emphasis>(NameListType_t*
        newType,CompoundAttributeDef_t* compoundAttr)</para>

        <para>Adds the compound attribute definition <emphasis
        role="bold">compoundAttr</emphasis> to the name list type <emphasis
        role="bold">newType</emphasis>.</para>

        <para>Returns a value &gt;= 0 upon success, otherwise -1.</para>
      </sect2>

      <sect2>
        <title>addAttributeToGroup</title>

        <para>herr_t <emphasis
        role="bold">addAttributeToGroup</emphasis>(NameListGroup_t* group,
        NameListAttribute_t* attr)</para>

        <para>Adds the attribute <emphasis role="bold">attr</emphasis> to the
        group <emphasis role="bold">group</emphasis>.</para>

        <para>Returns 0 upon success otherwise -1.</para>
      </sect2>

      <sect2>
        <title>addAttributeToDataset</title>

        <para>herr_t <emphasis
        role="bold">addAttributeToDataset</emphasis>(NameListDataset_t* dset,
        NameListAttribute_t* attr)</para>

        <para>Adds the attribute <emphasis role="bold">attr</emphasis> to the
        dataset <emphasis role="bold">dset</emphasis>.</para>

        <para>Returns 0 upon success otherwise -1.</para>
      </sect2>

      <sect2>
        <title>freeCompoundAttribute</title>

        <para>void <emphasis
        role="bold">freeCompoundAttribute</emphasis>(CompoundAttributeDef_t*
        attr)</para>

        <para>Deallocates the compound attribute definition <emphasis
        role="bold">attr</emphasis>.</para>

        <para>Returns nothing.</para>
      </sect2>

      <sect2>
        <title>freeAttribute</title>

        <para>void <emphasis
        role="bold">freeAttribute</emphasis>(NameListAttribute_t* attr)</para>

        <para>Deallocates the attribute <emphasis
        role="bold">attr</emphasis>.</para>

        <para>Returns nothing.</para>
      </sect2>

      <sect2>
        <title>freeNameListType</title>

        <para>void <emphasis
        role="bold">freeNameListType</emphasis>(NameListType_t* type)</para>

        <para>Deallocates the name list type <emphasis
        role="bold">type</emphasis>.</para>

        <para>Returns nothing.</para>
      </sect2>

      <sect2>
        <title>freeInternalDataset</title>

        <para>void <emphasis
        role="bold">freeInternalDataset</emphasis>(NameListDataset_t*
        dset)</para>

        <para>Deallocates the internals for the dataset <emphasis
        role="bold">dset</emphasis>.</para>

        <para>Returns nothing.</para>
      </sect2>

      <sect2>
        <title>freeDataset</title>

        <para>void <emphasis
        role="bold">freeDataset</emphasis>(NameListDataset_t* dset)</para>

        <para>Deallocates the dataset <emphasis
        role="bold">dset</emphasis>.</para>

        <para>Returns nothing.</para>
      </sect2>

      <sect2>
        <title>addTypeToLocalGroup</title>

        <para>herr_t <emphasis
        role="bold">addTypeToLocalGroup</emphasis>(NameListGroup_t* group,
        NameListType_t* type)</para>

        <para>Adds the type <emphasis role="bold">type</emphasis> to the local
        list of types in the group <emphasis
        role="bold">group</emphasis>.</para>

        <para>Returns a value &gt;= 0 upon success otherwise -1.</para>
      </sect2>

      <sect2>
        <title>addTypeToGlobalGroup</title>

        <para>herr_t <emphasis
        role="bold">addTypeToGlobalGroup</emphasis>(NameListGroup_t* group,
        NameListType_t* type)</para>

        <para>Adds the type <emphasis role="bold">type</emphasis> to the
        global list of types in the group <emphasis
        role="bold">group</emphasis>.</para>

        <para>Returns a value &gt;= 0 upon success otherwise -1.</para>
      </sect2>

      <sect2>
        <title>doesTypeExistInGlobalGroup</title>

        <para>int <emphasis
        role="bold">doesTypeExistInGlobalGroup</emphasis>(NameListGroup_t*
        grp,unsigned long* objno)</para>

        <para>Searches the global list of types in the group <emphasis
        role="bold">grp</emphasis> if any occurence of the <emphasis
        role="bold">objno</emphasis> exists.</para>

        <para><emphasis role="bold">grp</emphasis>: The group that should be
        searched in.</para>

        <para><emphasis role="bold">objno</emphasis>: An list of two <emphasis
        role="bold">unsigned long</emphasis>'s.</para>

        <para>Returns the index number in the global list if an occurance was
        found otherwise -1.</para>
      </sect2>

      <sect2>
        <title>doesTypeExistInLocalGroup</title>

        <para>int <emphasis
        role="bold">doesTypeExistInLocalGroup</emphasis>(NameListGroup_t*
        grp,unsigned long* objno)</para>

        <para>Searches the local list of types in the group <emphasis
        role="bold">grp</emphasis> if any occurence of the <emphasis
        role="bold">objno</emphasis> exists.</para>

        <para><emphasis role="bold">grp</emphasis>: The group that should be
        searched in.</para>

        <para><emphasis role="bold">objno</emphasis>: A list of two <emphasis
        role="bold">unsigned long</emphasis>'s.</para>

        <para>Returns the index number in the local list if an occurance was
        found otherwise -1.</para>
      </sect2>

      <sect2>
        <title>removeTypeFromLocalGroup</title>

        <para>NameListType_t* <emphasis
        role="bold">removeTypeFromLocalGroup</emphasis>(NameListGroup_t*
        group,unsigned long* objno)</para>

        <para>Removes the type with a matching <emphasis
        role="bold">objno</emphasis> from the group <emphasis
        role="bold">group</emphasis>'s list of local types and returns the
        type.</para>

        <para><emphasis role="bold">group</emphasis>: The group that should be
        searched.</para>

        <para><emphasis role="bold">objno</emphasis>: A list of two <emphasis
        role="bold">unsigned long</emphasis>'s.</para>

        <para>Returns the type with a matching object number if it was found,
        otherwise NULL</para>
      </sect2>

      <sect2>
        <title>removeTypeFromGlobalGroup</title>

        <para>NameListType_t* <emphasis
        role="bold">removeTypeFromGlobalGroup</emphasis>(NameListGroup_t*
        group,unsigned long* objno)</para>

        <para>Removes the type with a matching <emphasis
        role="bold">objno</emphasis> from the group <emphasis
        role="bold">group</emphasis>'s list of global types and returns the
        type.</para>

        <para><emphasis role="bold">group</emphasis>: The group that should be
        searched.</para>

        <para><emphasis role="bold">objno</emphasis>: A list of two <emphasis
        role="bold">unsigned long</emphasis>'s.</para>

        <para>Returns the type with a matching object number if it was found,
        otherwise NULL</para>
      </sect2>

      <sect2>
        <title>displayDataBuffer</title>

        <para>void <emphasis role="bold">displayDataBuffer</emphasis>(unsigned
        char* data, const char*fmt, int ndims, hsize_t* dims, size_t typeSize,
        int offs, int addNewline)</para>

        <para>Displays the data in a format similar to the one produced when
        using <emphasis role="bold">h5dump</emphasis> distributed with the
        HDF5 distribution.</para>

        <para><emphasis role="bold">data</emphasis>: A pointer to the
        data.</para>

        <para><emphasis role="bold">fmt</emphasis>: The hlhdf string
        representation of the dataformat.</para>

        <para><emphasis role="bold">ndims</emphasis>: The rank of the
        data.</para>

        <para><emphasis role="bold">dims</emphasis>: The dimensions of the
        data.</para>

        <para><emphasis role="bold">typeSize</emphasis>: The size of each
        value.</para>

        <para><emphasis role="bold">offs</emphasis>: The number of blanks that
        should be padded before the data.</para>

        <para><emphasis role="bold">addNewline</emphasis>: If a linebreak
        should be added or not, 1 means add linebreak.</para>

        <para>Returns nothing.</para>
      </sect2>

      <sect2>
        <title>displayCompoundDataset</title>

        <para>void <emphasis
        role="bold">displayCompoundDataset</emphasis>(unsigned char*
        data,NameListType_t* type,int ndims, hsize_t* dims, int offs)</para>

        <para>Displays a compound dataset in a format similar to the one
        produced when using <emphasis role="bold">h5dump</emphasis>
        distributed with the HDF5 distribution.</para>

        <para><emphasis role="bold">data</emphasis>: The data pointer.</para>

        <para><emphasis role="bold">type</emphasis>: The compound type
        definition.</para>

        <para><emphasis role="bold">ndims</emphasis>: The rank of the
        data.</para>

        <para><emphasis role="bold">dims</emphasis>: The dimensions of the
        data.</para>

        <para><emphasis role="bold">offs</emphasis>: The number of blanks that
        should be padded before the data.</para>

        <para>Returns nothing</para>
      </sect2>

      <sect2>
        <title>displayCompoundAttributeDef</title>

        <para>void <emphasis
        role="bold">displayCompoundAttributeDef</emphasis>(CompoundAttributeDef_t*
        def,int offs)</para>

        <para>Displays one attribute in a compound attribute in a format
        similar to the one produced when using <emphasis
        role="bold">h5dump</emphasis> distributed with the HDF5
        distribution.</para>

        <para><emphasis role="bold">def</emphasis>: The compound attribute
        definition.</para>

        <para><emphasis role="bold">offs</emphasis>: The number of blanks that
        should be padded before the data.</para>

        <para>Returns nothing</para>
      </sect2>

      <sect2>
        <title>displayType</title>

        <para>void <emphasis
        role="bold">displayType</emphasis>(NameListType_t* type, int
        offs)</para>

        <para>Displays one datatype in a format similar to the one produced
        when using <emphasis role="bold">h5dump</emphasis> distributed with
        the HDF5 distribution.</para>

        <para><emphasis role="bold">type</emphasis>: The datatype to
        display.</para>

        <para><emphasis role="bold">offs</emphasis>: The number of blanks that
        should be padded before the data.</para>

        <para>Returns nothing.</para>
      </sect2>

      <sect2>
        <title>displayAttribute</title>

        <para>void <emphasis
        role="bold">displayAttribute</emphasis>(NameListAttribute_t* attr,int
        offs)</para>

        <para>Displays one attribute in a format similar to the one produced
        when using <emphasis role="bold">h5dump</emphasis> distributed with
        the HDF5 distribution.</para>

        <para><emphasis role="bold">attr</emphasis>: The attribute to
        display.</para>

        <para><emphasis role="bold">offs</emphasis>: The number of blanks that
        should be padded before the data.</para>

        <para>Returns nothing.</para>
      </sect2>

      <sect2>
        <title>displayDataset</title>

        <para>void <emphasis
        role="bold">displayDataset</emphasis>(NameListDataset_t* dset, int
        offs)</para>

        <para>Displays one dataset in a format similar to the one produced
        when using <emphasis role="bold">h5dump</emphasis> distributed with
        the HDF5 distribution.</para>

        <para><emphasis role="bold">dset</emphasis>: The dataset to
        display.</para>

        <para><emphasis role="bold">offs</emphasis>: The number of blanks that
        should be padded before the data.</para>

        <para>Returns nothing.</para>
      </sect2>

      <sect2>
        <title>displayGroup</title>

        <para>void <emphasis
        role="bold">displayGroup</emphasis>(NameListGroup_t* grp,int
        offs)</para>

        <para>Displays one group in a format similar to the one produced when
        using <emphasis role="bold">h5dump</emphasis> distributed with the
        HDF5 distribution. This function will recursively go through all
        sub-groups belonging to this group.</para>

        <para><emphasis role="bold">grp</emphasis>: The group to
        display.</para>

        <para><emphasis role="bold">offs</emphasis>: The number of blanks that
        should be padded before the data.</para>

        <para>Returns nothing.</para>
      </sect2>

      <sect2>
        <title>readHlHdfFile</title>

        <para>NameListGroup_t* <emphasis
        role="bold">readHlHdfFile</emphasis>(const char* filename)</para>

        <para>Recursively reads a complete HDF5 file with name <emphasis
        role="bold">filename</emphasis> and builds a complete tree
        structure.</para>

        <para>Returns a pointer to a <emphasis
        role="bold">NameListGroup_t</emphasis> instance upon success,
        otherwise NULL.</para>
      </sect2>

      <sect2>
        <title>readHlHdfFileFrom</title>

        <para>NameListGroup_t* <emphasis
        role="bold">readHlHdfFileFrom</emphasis>(const char* filename, const
        char* from)</para>

        <para>Recursively reads an HDF5 file with name <emphasis
        role="bold">filename</emphasis> from the group <emphasis
        role="bold">from</emphasis> and builds a complete tree
        structure.</para>

        <para>Returns a pointer to a <emphasis
        role="bold">NameListGroup_t</emphasis> instance upon success,
        otherwise NULL.</para>
      </sect2>

      <sect2>
        <title>read_hlhdf_free</title>

        <para>void <emphasis
        role="bold">read_hlhdf_free</emphasis>(NameListGroup_t* group)</para>

        <para>Frees a HDF5 tree structure that has been read by using either
        <emphasis role="bold">readHlHdfFile</emphasis> or <emphasis
        role="bold">readHlHdfFileFrom</emphasis>. Be aware that this function
        must be used if one of the two functions above was used since it knows
        how the tree structure was built.</para>

        <para>Returns nothing.</para>
      </sect2>
    </sect1>
  </chapter>

  <chapter>
    <title>Creating your own HDF5 product</title>

    <para>When creating your own HDF5 product, there are two header files that
    should be included, <emphasis role="bold">read_vhlhdf.h</emphasis> and
    <emphasis role="bold">write_vhlhdf.h</emphasis>.</para>

    <para>When compiling a binary, there are three libraries that must be
    linked in; these are <emphasis role="bold">libhlhdf.a</emphasis>,
    <emphasis role="bold">libhdf5.a</emphasis> and <emphasis
    role="bold">libz.a</emphasis>. It is also possible to link the shared
    library <emphasis role="bold">libhdf5.so</emphasis> instead of <emphasis
    role="bold">libhdf5.a</emphasis>.</para>

    <para>The HL-HDF package was installed with a hldef.mk file that can be
    included in your own Makefile in order to get the correct paths to both
    the zlib and the hdf5 library. It also contains information on which
    C++-compiler the HL-HDF package was compiled with and some other
    goodies.</para>

    <para>A simple Makefile could look like this:</para>

    <literallayout>
include /usr/local/hlhdf/mkf/hldef.mk

HLHDF_INCDIR = -I/usr/local/hlhdf/include
HLHDF_LIBDIR = -L/usr/local/hlhdf/lib

CFLAGS = $(OPTS) $(DEFS) -I. $(ZLIB_INCDIR) $(HDF5_INCDIR) \
         $(HLHDF_INCDIR)

LDFLAGS = -L. $(ZLIB_LIBDIR) $(HDF5_LIBDIR) $(HLHDF_LIBDIR)

LIBS = -lhlhdf -lhdf5 -lz -lm

TARGET=myTestProgram
SOURCES=test_program.c
OBJECTS=$(SOURCES:.c=.o)

all: $(TARGET)

$(TARGET): $(OBJECTS)
           $(CC) -o $@ $(LDFLAGS) $(OBJECTS) $(LIBS)

clean:
           @\rm -f *.o *~ so_locations core

distclean: clean
           @\rm -f $(TARGET)

distribution:
           @echo "Would bring the latest revision upto date"

install:
           @$(HL_INSTALL) -f -o -C $(TARGET) ${MY_BIN_PATH}/$(TARGET)
      </literallayout>

    <para>Now, when the Makefile has been created, it might be a good idea to
    write your own HDF5 product. The following example will create a dataset
    with a two-dimensional array of integers, and two attributes connected to
    this dataset. It will also create a group containing one attribute.</para>

    <literallayout>
#include &lt;read_vhlhdf.h&gt;
#include &lt;write_vhlhdf.h&gt;

int main(int argc, char** argv)
{
  HL_NodeList* aList=NULL;
  HL_Node* aNode=NULL;
  int* anArray=NULL;
  int anIntValue;
  float aFloatValue;
  hsize_t dims[]={10,10};
  int npts=100;
  int i;

  initHlHdf();  /* Initialize the HL-HDF library */
  debugHlHdf(2); /* Activate debugging */

  if(!(aList = newHL_NodeList())) {
    fprintf(stderr,"Failed to allocate nodelist");
    goto fail;
  }

  if(!(anArray = malloc(sizeof(int)*npts))) {
    fprintf(stderr,"Failed to allocate memory for array.");
    goto fail;
  }
  for(i=0;i&lt;npts;i++)
    anArray[i]=i;

  addNode(aList,(aNode = newHL_Group("/group1")));
  addNode(aList,(aNode = newHL_Attribute("/group1/attribute1")));
  anIntValue=10;
  setScalarValue(aNode,sizeof(anIntValue),(unsigned char*)&amp;anIntValue,"int",-1);

  addNode(aList,(aNode = newHL_Dataset("/dataset1")));
  setArrayValue(aNode,sizeof(int),2,dims,(unsigned char*)anArray,"int",-1);

  addNode(aList,(aNode = newHL_Attribute("/dataset1/attribute2")));
  anIntValue=20;
  setScalarValue(aNode,sizeof(anIntValue),(unsigned char*)&amp;anIntValue,"int",-1);

  addNode(aList,(aNode = newHL_Attribute("/dataset1/attribute3")));
  aFloatValue=99.99;
  setScalarValue(aNode,sizeof(aFloatValue),(unsigned char*)&amp;aFloatValue,
                 "float",-1);

  strcpy(aList-&gt;filename,"written_hdffile.hdf");
  writeNodeList(aList,6);

  freeHL_NodeList(aList);
  exit(0);
  return 0; /* Won't come here */
 fail:
  freeHL_NodeList(aList);
  exit(1);
  return 1; /* Won't come here */
}
      </literallayout>

    <para>When you have created your own HDF5 product, it might be a good idea
    to create some code for reading this file and checking its
    contents.</para>

    <literallayout>
#include &lt;read_vhlhdf.h&gt;
#include &lt;write_vhlhdf.h&gt;

int main(int argc, char** argv)
{
  HL_NodeList* aList=NULL;
  HL_Node* aNode=NULL;
  int* anArray=NULL;
  int anIntValue;
  float aFloatValue;
  int npts;
  int i;

  initHlHdf();  /* Initialize the HL-HDF library */
  debugHlHdf(2); /* Activate debugging */

  if(!(aList = readHL_NodeList("written_hdffile.hdf"))) {
    fprintf(stderr,"Failed to read nodelist\n");
    goto fail;
  }

  selectAllNodes(aList);  /* Select everything for retrival */

  fetchMarkedNodes(aList);

  if((aNode = getNode(aList,"/group1")))
    printf("%s exists\n",aNode-&gt;name);

  if((aNode = getNode(aList,"/group1/attribute1"))) {
    memcpy(&amp;anIntValue,aNode-&gt;data,aNode-&gt;dSize);
    printf("%s exists and have value %d\n",aNode-&gt;name,anIntValue);
  }

  if((aNode = getNode(aList,"/dataset1"))) {
    anArray = (int*)aNode-&gt;data;
    npts = 1;
    for(i=0;i&lt;aNode-&gt;ndims;i++)
      npts*=aNode-&gt;dims[i];
    printf("%s exists and has the values:\n",aNode-&gt;name);
    for(i=0;i&lt;npts;i++) {
      printf("%d ", anArray[i]);
      if((i%aNode-&gt;dims[0])==0) {
        printf("\n");
      }
    }
    printf("\n");
  }

  if((aNode = getNode(aList,"/dataset1/attribute2"))) {
    memcpy(&amp;anIntValue,aNode-&gt;data,aNode-&gt;dSize);
    printf("%s exists and have the value %d\n",aNode-&gt;name,anIntValue);
  }

  if((aNode = getNode(aList,"/dataset1/attribute3"))) {
    memcpy(&amp;aFloatValue,aNode-&gt;data,aNode-&gt;dSize);
    printf("%s exists and have the value %f\n",aNode-&gt;name,aFloatValue);
  }
  freeHL_NodeList(aList);
  exit(0);
  return 0; /* Never reached */
 fail:
  freeHL_NodeList(aList);
  exit(1);
  return 1; /* Never reached */
}
      </literallayout>

      <para>
        A small example on how to reroute the error messages is shown below, currently there
        is no similar functionality for the _pyhl module.
      </para>
      <literallayout>
#include &lt;vhlhdf.h&gt;
#include &lt;hlhdf_debug.h&gt;
#include &lt;read_vhlhdf.h&gt;

void hlhdf_error_handler(char* filename, int lineno, HL_Debug lvl, const char* fmt, ...)
{
   va_list alist;
   char errbuff[512];
   va_start(alist,fmt);
   
   fprintf(stdout,"&lt;hlhdferror&gt;\n");
   fprintf(stdout," &lt;filename&gt;%s&lt;/filename&gt;\n",filename);
   fprintf(stdout," &lt;linenumber&gt;%d&lt;/linenumber&gt;\n",lineno);
   fprintf(stdout," &lt;level&gt;%d&lt;/level&gt;\n",lvl);
   vsprintf(errbuff,fmt,alist);
   fprintf(stdout," &lt;message&gt;%s&lt;/message&gt;\n",errbuff);
   fprintf(stdout,"&lt;/hlhdferror&gt;\n");
}

void hdf5_error_handler(int n, H5E_error_t* rowmsg)
{
   fprintf(stdout,"&lt;hdf5error&gt;\n");
   fprintf(stdout," &lt;filename&gt;%s&lt;/filename&gt;\n",rowmsg->file_name);
   fprintf(stdout," &lt;linenumber&gt;%d&lt;/linenumber&gt;\n",rowmsg->line);
   fprintf(stdout," &lt;funcname&gt;%s&lt;/funcname&gt;\n",rowmsg->func_name);
   fprintf(stdout," &lt;desc&gt;%s&lt;/desc&gt;\n",rowmsg->desc);
   fprintf(stdout,"&lt;/hdf5error&gt;\n");
}

int main(int argc, char** argv)
{
   HL_NodeList* nodelist;
   initHlHdf();
   enableErrorReporting();
   HL_setDebugFunction(hlhdf_error_handler);
   HL_setHdf5ErrorFunction(hdf5_error_handler);
   nodelist = readHL_NodeList("thisdoesnotexist.xxx");
   return 0;
}
      </literallayout>
  </chapter>

  <chapter>
    <title>Example Programs</title>

    <para>Three example programs have been provided with HL-HDF. Two of them
    are modelled after the BUFR software developed and maintained by the
    EUMETNET Operational Programme for the Exchange of Weather Radar
    Information (OPERA). This software has two programs called <emphasis
    role="bold">encbufr</emphasis> and <emphasis
    role="bold">decbufr</emphasis> used to encode and decode BUFR messages
    to/from an ASCII file containing header information and raw data in a
    binary file. The third example is modelled after a program called
    <emphasis role="bold">griblist</emphasis> developed by SMHI to query the
    contents of a GRIB file. GRIB and BUFR are format standards specified by
    the World Meteorological Organization.</para>

    <sect1>
      <title>hlenc</title>

      <para>Encodes raw binary data in one file and an ASCII file containing
      header information, into an HDF5 file.</para>

      <para><emphasis role="bold">hlenc <emphasis
      role="bold">[</emphasis>-hdv<emphasis role="bold">]</emphasis> <emphasis
      role="bold">[</emphasis>-z compression<emphasis role="bold">]</emphasis>
      -i inputprefix -o outputfile</emphasis></para>

      <para><emphasis role="bold">[-h]</emphasis> Prints a help text.</para>

      <para><emphasis role="bold">[-d]</emphasis> Prints debugging
      information.</para>

      <para><emphasis role="bold">[-v]</emphasis> Prints the version
      number.</para>

      <para><emphasis role="bold">[-z compression]</emphasis> Sets the
      compression level, can be in the range <emphasis
      role="bold">0</emphasis> to <emphasis role="bold">9</emphasis> where
      <emphasis role="bold">0</emphasis> is no compression and <emphasis
      role="bold">9</emphasis> is the highest compression.</para>

      <para><emphasis role="bold">-i inputprefix</emphasis> Specifies the
      prefix for the input files, the files that will be read are
      &lt;inputprefix&gt;.info and &lt;inputprefix&gt;.data.</para>

      <para><emphasis role="bold">-o outputfile</emphasis> Specifies the name
      of the HDF5 file to be generated. The file with extension .info should
      have the following apperance: DATATYPE: <emphasis
      role="bold">[</emphasis>ATTRIBUTE or DATASET<emphasis
      role="bold">]</emphasis> FIELDNAME: <emphasis
      role="bold">[</emphasis>name of the field, e.g. '/attr1'<emphasis
      role="bold">]</emphasis> DATASIZE: <emphasis
      role="bold">[</emphasis>size of the datatype in bytes<emphasis
      role="bold">]</emphasis> DATAFORMAT: <emphasis
      role="bold">[</emphasis>string representation of the datatype, e.g.
      int<emphasis role="bold">]</emphasis> DIMS: <emphasis
      role="bold">[</emphasis>the dimension of the data embraced by [], e.g.
      [10,10]<emphasis role="bold">]</emphasis> The file with extension .data
      should contain raw binary data with native byte order.</para>
    </sect1>

    <sect1>
      <title>hldec</title>

      <para>Decodes an HDF5 file into a binary data file and an ASCII info
      file.</para>

      <para><emphasis role="bold">hldec <emphasis
      role="bold">[</emphasis>-hdv<emphasis role="bold">]</emphasis> -i
      inputfile -f fieldname -o outputprefix</emphasis></para>

      <para><emphasis role="bold">[-h]</emphasis> Prints an help text.</para>

      <para><emphasis role="bold"><emphasis><emphasis
      role="bold">[-d]</emphasis> </emphasis></emphasis>Prints debugging
      information.</para>

      <para><emphasis role="bold"><emphasis
      role="bold">[</emphasis>-v<emphasis role="bold">]</emphasis></emphasis>
      Prints the version number.</para>

      <para><emphasis role="bold">-i inputfile</emphasis> Specifies the HDF5
      file to be decoded.</para>

      <para><emphasis role="bold">-f fieldname</emphasis> Specifies the
      fieldname to be decoded, e.g. '/dataset1'.</para>

      <para><emphasis role="bold">-o outputprefix</emphasis> Specifies the
      prefix for the output files, the files that will be generated are
      &lt;outputprefix&gt;.info and &lt;outputprefix&gt;.data.</para>

      <para>The file with extension .info will get the following apperance:
      DATATYPE: <emphasis role="bold">[</emphasis>ATTRIBUTE or
      DATASET<emphasis role="bold">]</emphasis> FIELDNAME: <emphasis
      role="bold">[</emphasis>name of the field, e.g. '/attr1'<emphasis
      role="bold">]</emphasis> DATASIZE: <emphasis
      role="bold">[</emphasis>size of the datatype in bytes<emphasis
      role="bold">]</emphasis> DATAFORMAT: <emphasis
      role="bold">[</emphasis>string representation of the datatype, e.g.
      int<emphasis role="bold">]</emphasis> DIMS: <emphasis
      role="bold">[</emphasis>the dimension of the data embraced by [], e.g.
      [10,10]<emphasis role="bold">]</emphasis> The file with extension .data
      will be saved in byteformat with native byte order.</para>
    </sect1>

    <sect1>
      <title>hllist</title>

      <para>Lists the nodes in an HDF5 file.</para>

      <para><emphasis role="bold">hllist <emphasis
      role="bold">[-hdv]</emphasis> hdf5file</emphasis></para>

      <para><emphasis role="bold"><emphasis
      role="bold">[</emphasis>-h<emphasis role="bold">]</emphasis></emphasis>
      Prints a help text.</para>

      <para><emphasis role="bold"><emphasis
      role="bold">[-d]</emphasis></emphasis> Prints debugging
      information.</para>

      <para><emphasis role="bold"><emphasis
      role="bold">[-v]</emphasis></emphasis> Prints the version number.</para>

      <para><emphasis role="bold">hdf5file</emphasis> Is the HDF5 file to be
      listed.</para>
    </sect1>
  </chapter>

  <chapter>
    <title>Python Interface - PyHL</title>

    <para>PyHL is just like the HL-HDF library in that it allows the user to
    work with HDF5 at a high level. PyHL is designed to work at the highest
    level of abstraction using the Python programming language, since Python
    allows the user to interact directly with HDF5 files. In fact, PyHL is
    nothing more than a wrapper around HL-HDF but with some additional
    functionality which is only available in very high level languages such as
    Python. Like HL-HDF, it is up to the user to define appropriate ways of
    representing data and using the building blocks available in PyHL to store
    the data in HDF5.</para>

    <para>(PyHL is pronounced "pile", which is an appropriate description of a
    heirarchy ...)</para>

    <sect1>
      <title>Compilation and installation</title>

      <para>The Python programming language, version 1.5.2, is required along
      with the Numeric package. Python is found at the Corporation for
      National Research Initiatives at <ulink
      url="http://www.python.org/">http://www.python.org </ulink>and Numeric
      is found at the Source Forge <ulink
      url="http://numpy.sourceforge.net">http://numpy.sourceforge.net</ulink>.</para>
    </sect1>

    <sect1>
      <title>Create module _pyhl</title>

      <para>If the configure script was not called with <emphasis
      role="bold">--with-python=no</emphasis> the _pyhl module should be
      compiled together with the rest of the code. If the configure script was
      called with <emphasis role="bold">--with-python=no</emphasis>, then the
      best thing is to rebuild the whole HL-HDF package (with <emphasis
      role="bold">--with-python=yes</emphasis>) and installation as descriped
      in Sections \ref{compilation} and \ref{installation}.</para>

      <para><emphasis role="bold">NOTE:</emphasis> <emphasis
      role="bold">Python version 1.5.2 is required to compile _pyhl; otherwise
      there will be unresolved symbols. Also, be aware that the hdf5 library
      is linked dynamically which requires that the LD_LIBRARY_PATH contains
      the path to where libhdf5.so has been installed. contains the path to
      where libhdf5.so has been installed.</emphasis></para>
    </sect1>

    <sect1>
      <title>Library Reference</title>

      <para>The _pyhl module defines the IO access for reading/writing HDF5
      files. The module implements two classes for building an HDF5 file
      representation. The <emphasis role="bold">nodelist</emphasis> class
      implements a list that should represent the file itself. The <emphasis
      role="bold">node</emphasis> class represents the items in the HDF5 file.
      The <emphasis role="bold">nodelist</emphasis> contain several <emphasis
      role="bold">node</emphasis>'s for building the HDF5 file. You can use
      this interface to write Python programs that interfact with HDF5
      files.</para>

      <sect2>
        <title>_pyhl interfaces</title>

        <sect3>
          <title>is_file_hdf5</title>

          <para><emphasis role="bold">is_file_hdf5</emphasis>(filename)</para>

          <para>Checks whether <emphasis role="bold">filename</emphasis> is an
          HDF5 file.</para>

          <para>Returns 1 if it is and 0 otherwise.</para>
        </sect3>

        <sect3>
          <title>nodelist</title>

          <para><emphasis role="bold">nodelist</emphasis>()</para>

          <para>Return a new instance of the <emphasis
          role="bold">nodelist</emphasis> class.</para>
        </sect3>

        <sect3>
          <title>node</title>

          <para><emphasis
          role="bold">node</emphasis>(nodetype,nodename[,compression
          object])</para>

          <para>Return a new instance of the <emphasis
          role="bold">node</emphasis>.</para>

          <para><emphasis role="bold">nodetype</emphasis> can be one of:
          <emphasis role="bold">ATTRIBUTE_ID</emphasis>, <emphasis
          role="bold">DATASET_ID</emphasis>, <emphasis
          role="bold">GROUP_ID</emphasis>, <emphasis
          role="bold">TYPE_ID</emphasis> and <emphasis
          role="bold">REFERENCE_ID</emphasis></para>

          <para><emphasis role="bold">nodename</emphasis> is the name of the
          node, for example <emphasis
          role="bold">/group1/group2/dataset1</emphasis>.</para>

          <para><emphasis role="bold">ATTRIBUTE_ID</emphasis> When creating a
          <emphasis role="bold">node</emphasis> and using this value, the node
          will become an attribute node.</para>

          <para><emphasis role="bold">DATASET_ID</emphasis> When creating a
          <emphasis role="bold">node</emphasis> and using this value, the node
          will become a dataset node.</para>

          <para><emphasis role="bold">GROUP_ID</emphasis> When creating a
          <emphasis role="bold">node</emphasis> and using this value, the node
          will become a group node.</para>

          <para><emphasis role="bold">TYPE_ID</emphasis> When creating a
          <emphasis role="bold">node</emphasis> and using this value, the node
          will become a datatype node.</para>

          <para><emphasis role="bold">REFERENCE_ID</emphasis> When creating a
          <emphasis role="bold">node</emphasis> and using this value, the node
          will become a reference node.</para>

          <para><emphasis role="bold">compression</emphasis> When creating a
          <emphasis role="bold">node</emphasis> it is possible to specify how
          the compression should be performed on this node.</para>
        </sect3>

        <sect3>
          <title>read_nodelist</title>

          <para><emphasis
          role="bold">read_nodelist</emphasis>(filename<emphasis
          role="bold">[</emphasis>,from<emphasis
          role="bold">]</emphasis>)</para>

          <para>Read the HDF5 file <emphasis role="bold">filename</emphasis>
          and build a <emphasis role="bold">nodelist</emphasis> with all the
          names. That is the data will not be read, just the names. If a
          nodelist is built from a group lower down in the hierarchy, then
          <emphasis role="bold">from</emphasis> can be specified. If all goes
          well, the <emphasis role="bold">nodelist</emphasis> is returned,
          otherwise an exception is thrown.</para>
        </sect3>

        <sect3>
          <title>compression</title>

          <para><emphasis
          role="bold">compression</emphasis>(compressiontype)</para>

          <para>Creates a compression object.</para>

          <para><emphasis role="bold">compressiontype</emphasis>: Can be
          either COMPRESSION_SZLIB or COMPRESSION_ZLIB.</para>
        </sect3>

        <sect3>
          <title>filecreationproperty</title>

          <para><emphasis role="bold">filecreationproperty</emphasis>()</para>

          <para>Creates a file creation property object.</para>
        </sect3>
      </sect2>

      <sect2>
        <title>nodelist</title>

        <sect3>
          <title>write</title>

          <para><emphasis role="bold">write</emphasis>(filename<emphasis
          role="bold">[</emphasis>,compression<emphasis
          role="bold">][</emphasis>,file creation property<emphasis
          role="bold">]</emphasis>)</para>

          <para>Write the instance to disk in HDF5 format.</para>

          <para><emphasis role="bold">compression</emphasis>: Can be either an
          int between 0-9 which is used to specify the ZLIB compression level
          where 0 is no compression and 9 is highest compression.</para>

          <para>Compression can also be specified by using the compression
          object that is accessable by using _pyhl.compression()</para>

          <para><emphasis role="bold">file creation property</emphasis>: Is
          used to tune how the file should be stored, it can be a good idea
          using the file creation properties when writing small files since it
          can give quite large savings on file size.</para>

          <para><emphasis role="bold">NOTE!</emphasis> This has been changed
          from previous versions of hlhdf. From now on, there is nothing
          called default compression level! The reason for this is that since
          it is possible to specify compression on a dataset by dataset level
          having a default compression level when writing would override the
          compression levels specified on node level.</para>
        </sect3>

        <sect3>
          <title>update</title>

          <para><emphasis role="bold">update</emphasis>(<emphasis
          role="bold">[</emphasis>,compression)<emphasis
          role="bold">]</emphasis></para>

          <para>Updates the instance. The default compression value is
          <emphasis role="bold">6</emphasis>. If another compression level is
          wanted, then the value can be between <emphasis
          role="bold">0</emphasis> for no compression and <emphasis
          role="bold">9</emphasis> for highest compression.</para>
        </sect3>

        <sect3>
          <title>addNode</title>

          <para><emphasis role="bold">addNode</emphasis>(node) Adds a node of
          class <emphasis role="bold">node</emphasis> to the end of the
          nodelist.</para>
        </sect3>

        <sect3>
          <title>getNodeNames</title>

          <para><emphasis role="bold">getNodeNames</emphasis>()</para>

          <para>Returns a dictionary with all the nodelists' node names as
          keys and the integer values <emphasis
          role="bold">ATTRIBUTE_ID</emphasis>, <emphasis
          role="bold">DATASET_ID</emphasis>, <emphasis
          role="bold">TYPE_ID</emphasis>, <emphasis
          role="bold">GROUP_ID</emphasis> and <emphasis
          role="bold">REFERENCE_ID</emphasis> as items.</para>
        </sect3>

        <sect3>
          <title>selectAll</title>

          <para><emphasis role="bold">selectAll</emphasis>()</para>

          <para>Marks all nodes in the nodelist for data retrival.</para>
        </sect3>

        <sect3>
          <title>selectNode</title>

          <para><emphasis role="bold">selectNode</emphasis>(nodename)</para>

          <para>Marks the node specified by <emphasis
          role="bold">nodename</emphasis> to be retrived.</para>
        </sect3>

        <sect3>
          <title>fetch</title>

          <para><emphasis role="bold">fetch</emphasis>()</para>

          <para>Fetches all nodes in the selected nodelist.</para>
        </sect3>

        <sect3>
          <title>getNode</title>

          <para><emphasis role="bold">getNode</emphasis>(nodename)</para>

          <para>Return the node with name <emphasis
          role="bold">nodename</emphasis>.</para>
        </sect3>
      </sect2>

      <sect2>
        <title>node</title>

        <sect3>
          <title>setScalarValue</title>

          <para><emphasis
          role="bold">setScalarValue</emphasis>(itemSize,data,typename,lhid)</para>

          <para>Sets a scalar value in the <emphasis
          role="bold">node</emphasis> instance.</para>

          <para><emphasis role="bold">itemSize</emphasis> is used for
          specifying the size of the value in bytes. It is not necessary to
          specify unless a compound type is set.</para>

          <para><emphasis role="bold">data</emphasis> is the data to be set in
          the node.</para>

          <para><emphasis role="bold">typename</emphasis> is the string
          representation of the datatype, for example <emphasis
          role="bold">int</emphasis>, <emphasis role="bold">string</emphasis>,
          <emphasis role="bold">compound</emphasis>, ...</para>

          <para><emphasis role="bold">lhid</emphasis> is the <emphasis
          role="bold">hid_t</emphasis> reference to the datatype, is not
          nessecary to specify unless a compound type is set.</para>

          <para><emphasis role="bold">NOTE:</emphasis> If the data to be set
          is of compound type, then the data should be of string type.</para>

          <para><emphasis role="bold">NOTE:</emphasis> If the node is a
          <emphasis role="bold">Reference</emphasis> node, the data should be
          set as a string type, where the data is the name of the referenced
          node.</para>
        </sect3>

        <sect3>
          <title>setArrayValue</title>

          <para><emphasis
          role="bold">setArrayValue</emphasis>(itemSize,dims,data,typename,lhid)</para>

          <para>Sets an array value in the <emphasis
          role="bold">node</emphasis> instance.</para>

          <para><emphasis role="bold">itemSize</emphasis> is used for
          specifying the size of the value in bytes. It is not nessecary to
          specify unless a compound type is set.</para>

          <para><emphasis role="bold">dims</emphasis> is a list of dimensions
          of the data.</para>

          <para><emphasis role="bold">data</emphasis> is the data to be set in
          the node.</para>

          <para><emphasis role="bold">typename</emphasis> is the string
          representation of the datatype, for example <emphasis
          role="bold">int</emphasis>, <emphasis role="bold">string</emphasis>,
          <emphasis role="bold">compound</emphasis>, ...</para>

          <para><emphasis role="bold">lhid</emphasis> is the <emphasis
          role="bold">hid_t</emphasis> reference to the datatype, is not
          nessecary to specify unless a compound type should be set.</para>

          <para><emphasis role="bold">NOTE:</emphasis> If the data to be set
          is of compound type, the data should be of string type.</para>
        </sect3>

        <sect3>
          <title>commit</title>

          <para><emphasis role="bold">commit</emphasis>(datatype)</para>

          <para>Marks a <emphasis role="bold">TYPE_ID</emphasis> node to be
          committed.</para>

          <para><emphasis role="bold">datatype</emphasis> is the <emphasis
          role="bold">hid_t</emphasis> reference to the datatype.</para>

          <para><emphasis role="bold">name</emphasis>()</para>

          <para>Returns the name of the <emphasis role="bold">node</emphasis>
          instance.</para>
        </sect3>

        <sect3>
          <title>type</title>

          <para><emphasis role="bold">type</emphasis>()</para>

          <para>Returns the type of the <emphasis role="bold">node</emphasis>
          instance.</para>
        </sect3>

        <sect3>
          <title>dims</title>

          <para><emphasis role="bold">dims</emphasis>()</para>

          <para>Returns a list of the dimensions of the <emphasis
          role="bold">node</emphasis> instance</para>
        </sect3>

        <sect3>
          <title>format</title>

          <para><emphasis role="bold">format</emphasis>()</para>

          <para>Returns the string representation of the <emphasis
          role="bold">node</emphasis>'s datatype.</para>
        </sect3>

        <sect3>
          <title>data</title>

          <para><emphasis role="bold">data</emphasis>()</para>

          <para>Returns the fixed data of the <emphasis
          role="bold">node</emphasis> instance.</para>

          <para><emphasis role="bold">NOTE:</emphasis> If the data is of
          compound type, the data will be returned as a string.</para>
        </sect3>

        <sect3>
          <title>rawdata</title>

          <para><emphasis role="bold">rawdata</emphasis>()</para>

          <para>Returns the raw data of the <emphasis
          role="bold">node</emphasis> instance.</para>

          <para><emphasis role="bold">NOTE:</emphasis> If the data is of
          compound type, the data will be returned as a string.</para>
        </sect3>

        <sect3>
          <title>compound_data</title>

          <para><emphasis role="bold">compound_data</emphasis>()</para>

          <para>Returns a dictionary with all attributes in the compund
          attribute, it only works if the <emphasis
          role="bold">node</emphasis> instance is a compound attribute.</para>
        </sect3>
      </sect2>

      <sect2>
        <title>compression</title>

        <para>The compression object does only contain various properties that
        is possible to set. Depending on what compression type that was
        specified when creating this object there are different parameters
        that can be used.</para>

        <para>If ZLIB_COMPRESSION was specified the only property that can be
        used is:</para>

        <para><emphasis role="bold">level</emphasis>: Specify level of
        compression between 0-9 where <emphasis role="bold">0</emphasis> means
        no compression and <emphasis role="bold">9</emphasis> means highest
        compression.</para>

        <para>If SZLIB_COMPRESSION was specified, there are two properties
        that can be set:</para>

        <para><emphasis role="bold">szlib_mask</emphasis>: This affects how
        the compression should be performed and can can be set up from two
        different sets of options.</para>

        <table>
          <title>SZLIB Compression options</title>

          <tgroup cols="2">
            <colspec align="left" colnum="1" colwidth="200" />

            <colspec align="left" colnum="2" colwidth="200" />

            <tbody>
              <row>
                <entry>H5_SZIP_CHIP_OPTION_MASK</entry>

                <entry>Compresses exactly as in hardware.</entry>
              </row>

              <row>
                <entry>H5_SZIP_ALLOW_K13_OPTION_MASK</entry>

                <entry>Allows k split = 13 compression mode. (Default)</entry>
              </row>

              <row>
                <entry>H5_SZIP_EC_OPTION_MASK</entry>

                <entry>Selects entropy coding method. (Default)</entry>
              </row>

              <row>
                <entry>H5_SZIP_NN_OPTION_MASK</entry>

                <entry>Selects nearest neighbor coding method.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>

        <para>The paired options are mutual exclusive, i.e. it is possible to
        set the szlib_mask to H5_SZIP_CHIP_OPTION_MASK|H5_SZIP_EC_OPTION_MASK
        but not to
        H5_SZIP_CHIP_OPTION_MASK|H5_SZIP_ALLOW_K13_OPTION_MASK.</para>

        <para><emphasis role="bold">szlib_px_per_block</emphasis>: The block
        size must be even, with typical values being 8,10,16 and 32. The more
        pixel values vary, the smaller this number should be.</para>
      </sect2>

      <sect2>
        <title>filecreationproperty</title>

        <para>The filecreationproperty object does only contain various
        properties that is possible to set. Depending on how the file should
        be created, there are different parameters that can be used.</para>

        <para><emphasis role="bold">version</emphasis>: This parameter is only
        for retrival, i.e it is not possible to change.</para>

        <para><emphasis role="bold">userblock</emphasis>: See the hdf5
        documentation for purpose of userblock</para>

        <para><emphasis role="bold">sizes</emphasis>: Is specified as a tuple
        of 2, (sizeof_addr,sizeof_size), see hdf5 documentation for further
        information</para>

        <para><emphasis role="bold">sym_k</emphasis>: Is specified as a tuple
        of 2, (ik,lk), see hdf5 documentation for further information</para>

        <para><emphasis role="bold">istore_k</emphasis>: See hdf5
        documentation for further information</para>

        <para><emphasis role="bold">meta_block_size</emphasis>: This is
        actually a file access property but have been inserted here anyway, If
        the value is set to 2048, then the default file access property will
        be used. For more information about meta_block_size, see the hdf5
        documentation.</para>
      </sect2>
    </sect1>

    <sect1>
      <title>Examples</title>

      <para>The creation of HDF5 files with PyHL is quite easy, and there are
      not to many things one has to know about the HDF5 internals. However, in
      order to build an HDF5 file, one has to understand that the file should
      be built sequentialy, i.e. it is not possible to create a subgroup to a
      group before the group has been created. Neither is it possible to
      create an attribute or a dataset in a group before the group has been
      created etc. In other words, always create the top nodes before trying
      to create nodes under them in the heirarchy.</para>

      <para>Another thing to bear in mind is that when the method <emphasis
      role="bold">addNode</emphasis> has been called the <emphasis
      role="bold">nodelist</emphasis> instance will take control over the
      node, so it will not be possible to alter the node after a call to
      <emphasis role="bold">addNode</emphasis> has been made.</para>

      <para>When working with compound types, remember that the data that is
      passed to <emphasis role="bold">setScalarValue</emphasis> and <emphasis
      role="bold">setArrayValue</emphasis> must be a Python string. Also when
      working with compound types, the <emphasis
      role="bold">itemSize</emphasis> and <emphasis
      role="bold">lhid</emphasis> has to be passed on, otherwise the compound
      data most likely will be corrupted.</para>

      <para>Also when working with compound types, be aware that the hdf5
      library has to be linked dynamically, otherwise it will not be possible
      to pass the <emphasis role="bold">hid_t</emphasis> references between
      the Python modules.</para>

      <para>Time to look at some simple examples.</para>

      <sect2>
        <title>Writing a simple HDF5 file</title>

        <literallayout>
import _pyhl
from Numeric import *

# Create an empty node list instance
aList = _pyhl.nodelist()

# Create an group called info
aNode = _pyhl.node(_pyhl.GROUP_ID,"/info")

# Add the node to the nodelist
# Remember that the nodelist takes responsibility
aList.addNode(aNode)

# Insert the attribute xscale in the group "/info"
aNode = _pyhl.node(_pyhl.ATTRIBUTE_ID,"/info/xscale")

# Set the value to a double with value 10.0
# Note the -1's that has been used since the data not is compaound
aNode.setScalarValue(-1,10.0,"double",-1)
aList.addNode(aNode)

# Similar for yscale,xsize and ysize
aNode = _pyhl.node(_pyhl.ATTRIBUTE_ID,"/info/yscale")
aNode.setScalarValue(-1,20.0,"double",-1)
aList.addNode(aNode)
aNode = _pyhl.node(_pyhl.ATTRIBUTE_ID,"/info/xsize")
aNode.setScalarValue(-1,10,"int",-1)
aList.addNode(aNode)
aNode = _pyhl.node(_pyhl.ATTRIBUTE_ID,"/info/ysize")
aNode.setScalarValue(-1,10,"int",-1)
aList.addNode(aNode)

# Add a description
aNode = _pyhl.node(_pyhl.ATTRIBUTE_ID,"/info/description")
aNode.setScalarValue(-1,"This is a simple example","string",-1)
aList.addNode(aNode)

# Add an array of data
myArray = arange(100)
myArray = array(myArray.astype('i'),'i')
myArray = reshape(myArray,(10,10))
aNode = _pyhl.node(_pyhl.DATASET_ID,"/data")

# Set the data as an array, note the list with [10,10] which
# Indicates that it is an array of 10x10 items
aNode.setArrayValue(-1,[10,10],myArray,"int",-1)
aList.addNode(aNode)

# And now just write the file as "simple_test.hdf" with
# Compression level 9 (highest compression)
aList.write("simple_test.hdf",9)
          </literallayout>

        <para>When checking this file with h5dump, the command syntax would
        be: <emphasis role="bold">prompt% h5dump simple_test.hdf</emphasis>
        And the result would be:</para>

        <literallayout>
HDF5 "simple_test.hdf" {
GROUP "/" {
   DATASET "data" {
      DATATYPE { H5T_STD_I32LE }
      DATASPACE { SIMPLE ( 10, 10 ) / ( 10, 10 ) }
      DATA {
         0, 1, 2, 3, 4, 5, 6, 7, 8, 9,
         10, 11, 12, 13, 14, 15, 16, 17, 18, 19,
         20, 21, 22, 23, 24, 25, 26, 27, 28, 29,
         30, 31, 32, 33, 34, 35, 36, 37, 38, 39,
         40, 41, 42, 43, 44, 45, 46, 47, 48, 49,
         50, 51, 52, 53, 54, 55, 56, 57, 58, 59,
         60, 61, 62, 63, 64, 65, 66, 67, 68, 69,
         70, 71, 72, 73, 74, 75, 76, 77, 78, 79,
         80, 81, 82, 83, 84, 85, 86, 87, 88, 89,
         90, 91, 92, 93, 94, 95, 96, 97, 98, 99
      }
   }
   GROUP "info" {
      ATTRIBUTE "xscale" {
         DATATYPE { H5T_IEEE_F64LE }
         DATASPACE { SCALAR }
         DATA {
            10
         }
      }
      ATTRIBUTE "yscale" {
         DATATYPE { H5T_IEEE_F64LE }
         DATASPACE { SCALAR }
         DATA {
            20
         }
      }
      ATTRIBUTE "xsize" {
         DATATYPE { H5T_STD_I32LE }
         DATASPACE { SCALAR }
         DATA {
            10
         }
      }
      ATTRIBUTE "ysize" {
         DATATYPE { H5T_STD_I32LE }
         DATASPACE { SCALAR }
         DATA {
            10
         }
      }
      ATTRIBUTE "description" {
         DATATYPE {
            { STRSIZE 25;
              STRPAD H5T_STR_NULLTERM;
              CSET H5T_CSET_ASCII;
              CTYPE H5T_C_S1;
            }
         }
         DATASPACE { SCALAR }
         DATA {
            "This is a simple example"
         }
      }
   }
}
}
          </literallayout>
      </sect2>

      <sect2>
        <title>Writing an HDF5 file containing a compound datatype</title>

        <para>This is a bit more complex since it requires the implementation
        of a Python C++-module that contains the datatype definition, and a
        couple of methods for converting data to a string and the other way
        around.</para>

        <para>There is a small example located in the <emphasis
        role="bold">hlhdf/pyhl</emphasis> directory called <emphasis
        role="bold">rave_info_type</emphasis> which implements a small
        compound type definition. Basically this module defines an object
        containing <emphasis role="bold">xscale</emphasis>, <emphasis
        role="bold">yscale</emphasis>,<emphasis role="bold">xsize</emphasis>
        and <emphasis role="bold">ysize</emphasis> variables. This module has
        also got a type class which should be used.</para>

        <literallayout>
import _pyhl
import _rave_info_type

# Create the rave info HDF5 type
typedef = _rave_info_type.type()

# Create the rave info HDF5 object
obj = _rave_info_type.object()

# Set the values
obj.xsize=10
obj.ysize=10
obj.xscale=150.0
obj.yscale=150.0

aList = _pyhl.nodelist()

# Create a datatype node
aNode = _pyhl.node(_pyhl.TYPE_ID,"/MyDatatype")

# Make the datatype named
aNode.commit(typedef.hid())
aList.addNode(aNode)

# Create an attribute containing the compound type
aNode = _pyhl.node(_pyhl.ATTRIBUTE_ID,"/myCompoundAttribute")

# Note that I use both itemSize and lhid
# Also note how I translate the compound object to a string
aNode.setScalarValue(typedef.size(),obj.tostring(),"compound",typedef.hid())
aList.addNode(aNode)

# Better create a dataset also with the compound type
obj.xsize=1
obj.ysize=1
aNode = _pyhl.node(_pyhl.DATASET_ID,"/myCompoundDataset")

# I use setArrayValue instead
aNode.setArrayValue(typedef.size(),[1],obj.tostring(),"compound",typedef.hid())
aList.addNode(aNode)

# And finally write the HDF5 file.
aList.write("compound_test.hdf")
          </literallayout>

        <para>When checking this file with h5dump, the command syntax would
        be: <emphasis role="bold">prompt% h5dump compound_test.hdf</emphasis>
        And the result would be:</para>

        <literallayout>
HDF5 "compound_test.hdf" {
GROUP "/" {
   ATTRIBUTE "myCompoundAttribute" {
      DATATYPE {
         H5T_STD_I32LE "xsize";
         H5T_STD_I32LE "ysize";
         H5T_IEEE_F64LE "xscale";
         H5T_IEEE_F64LE "yscale";
      }
      DATASPACE { SCALAR }
      DATA {
         {
            [ 10 ],
            [ 10 ],
            [ 150 ],
            [ 150 ]
         }
      }
   }
   DATATYPE "MyDatatype" {
      H5T_STD_I32LE "xsize";
      H5T_STD_I32LE "ysize";
      H5T_IEEE_F64LE "xscale";
      H5T_IEEE_F64LE "yscale";
   }
   DATASET "myCompoundDataset" {
      DATATYPE {
         "/MyDatatype"
      }
      DATASPACE { SIMPLE ( 1 ) / ( 1 ) }
      DATA {
         {
            [ 1 ],
            [ 1 ],
            [ 150 ],
            [ 150 ]
         }
      }
   }
}
}
          </literallayout>
      </sect2>

      <sect2>
        <title>Reading a simple HDF5 file</title>

        <para>The following example code will read the <emphasis
        role="bold">/info/xscale</emphasis>, <emphasis
        role="bold">/info/yscale</emphasis> and <emphasis
        role="bold">/data</emphasis> fields from the HDF5 file <emphasis
        role="bold">simple_test.hdf</emphasis>.</para>

        <literallayout>
# Read the file
aList = _pyhl.read_nodelist("simple_test.hdf")

# Select individual nodes, instead of all of them
aList.selectNode("/info/xscale")
aList.selectNode("/info/yscale")
aList.selectNode("/data")

# Fetch the data for selected nodes
aList.fetch()

# Print the data
aNode = aList.getNode("/info/xscale")
print "XSCALE=" + `aNode.data()`
aNode = aList.getNode("/info/yscale")
print "YSCALE=" + `aNode.data()`
aNode = aList.getNode("/data")
print "DATA=" + `aNode.data()`
          </literallayout>
      </sect2>

      <sect2>
        <title>Reading an HDF5 file containing a compound type</title>

        <para>This example shows how an HDF5 file containing a compound type
        in it can be read. It will read the file "compound_test.hdf" that was
        generated above. Note that this code might not be portable to any
        other machine due to the usage of the rawdata method.</para>

        <literallayout>
import _pyhl
import _rave_info_type

# There is no meaning creating the type
obj = _rave_info_type.object()
aList = _pyhl.read_nodelist("compound_test.hdf")

# Select everything for retrival
aList.selectAll()
aList.fetch()
aNode = aList.getNode("/myCompoundAttribute")

# Translate from the string representation to object
obj.fromstring(aNode.rawdata())

# Display the values
print "XSIZE="+`obj.xsize`
print "YSIZE="+`obj.ysize`
print "XSCALE="+`obj.xscale`
print "YSCALE="+`obj.yscale`
          </literallayout>
      </sect2>

      <sect2>
        <title>Reading an HDF5 file containing a compound type
        (alterntive)</title>

        <para>This example shows how an HDF5 file containing a compound type
        in it can be read. It will read the file "compound_test.hdf" that was
        generated above. This example should work on any supported
        platform.</para>

        <literallayout>
import _pyhl
import _rave_info_type

# There is no meaning creating the type
obj = _rave_info_type.object()
aList = _pyhl.read_nodelist("compound_test.hdf")

# Select everything for retrival
aList.selectAll()
aList.fetch()
aNode = aList.getNode("/myCompoundAttribute")

# Translate from the string representation to object
cdescr = obj.compound_data()
obj.xsize = cdescr["xsize"]
obj.ysize = cdescr["ysize"]
obj.xscale = cdescr["xscale"]
obj.yscale = cdescr["yscale"]

# Display the values
print "XSIZE="+`obj.xsize`
print "YSIZE="+`obj.ysize`
print "XSCALE="+`obj.xscale`
print "YSCALE="+`obj.yscale`
          </literallayout>
      </sect2>

      <sect2>
        <title>Creating a HDF5 image with a reference</title>

        <para>This example shows how it is possible to create a HDF5 that is
        viewable in for example the H5View visualization tool.</para>

        <literallayout>
import _pyhl
from Numeric import *

# Function for creating a dummy palette
def createPalette():
  a=zeros((256,3),'b')
  for i in range(0,256):
    a[i][0]=i
  return a

# Function for creating a dummy image}
def createImage():
  a=zeros((256,256),'b')
    for i in range(0,256):
      for j in range(0,256):
        a[i][j] = i
  return a

# Function for the HDF5 file
def create_test_image():
  a=_pyhl.nodelist()

  # First create the palette}
  b=_pyhl.node(_pyhl.DATASET_ID,"/PALETTE")
  c=createPalette()
  b.setArrayValue(1,[256,3],c,"uchar",-1)
  a.addNode(b)
  b=_pyhl.node(_pyhl.ATTRIBUTE_ID,"/PALETTE/CLASS")
  b.setScalarValue(-1,"PALETTE","string",-1)
  a.addNode(b)
  b=_pyhl.node(_pyhl.ATTRIBUTE_ID,"/PALETTE/PAL_VERSION")
  b.setScalarValue(-1,"1.2","string",-1)
  a.addNode(b)
  b=_pyhl.node(_pyhl.ATTRIBUTE_ID,"/PALETTE/PAL_COLORMODEL")
  b.setScalarValue(-1,"RGB","string",-1)
  a.addNode(b)
  b=_pyhl.node(_pyhl.ATTRIBUTE_ID,"/PALETTE/PAL_TYPE")
  b.setScalarValue(-1,"STANDARD8","string",-1)
  a.addNode(b)

  # Now create the image to display}
  b=_pyhl.node(_pyhl.DATASET_ID,"/IMAGE1")
  c=createImage()
  b.setArrayValue(1,[256,256],c,"uchar",-1)
  a.addNode(b)
  b=_pyhl.node(_pyhl.ATTRIBUTE_ID,"/IMAGE1/CLASS")
  b.setScalarValue(-1,"IMAGE","string",-1)
  a.addNode(b)
  b=_pyhl.node(_pyhl.ATTRIBUTE_ID,"/IMAGE1/IMAGE_VERSION")
  b.setScalarValue(-1,"1.2","string",-1)
  a.addNode(b)

  # Finally insert the reference}
  b=_pyhl.node(_pyhl.REFERENCE_ID,"/IMAGE1/PALETTE")
  b.setScalarValue(-1,"/PALETTE","string",-1)
  a.addNode(b)

  a.write("ahewrittenimage.hdf")

# The main function}
if __name__=="__main__"
  create_test_image()
          </literallayout>
      </sect2>
    </sect1>
  </chapter>
</book>